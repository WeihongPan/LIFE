{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weihong/anaconda3/envs/pytorch/lib/python3.8/site-packages/cupy/_environment.py:435: UserWarning: \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  CuPy may not function correctly because multiple CuPy packages are installed\n",
      "  in your environment:\n",
      "\n",
      "    cupy, cupy-cuda100\n",
      "\n",
      "  Follow these steps to resolve this issue:\n",
      "\n",
      "    1. For all packages listed above, run the following command to remove all\n",
      "       existing CuPy installations:\n",
      "\n",
      "         $ pip uninstall <package_name>\n",
      "\n",
      "      If you previously installed CuPy via conda, also run the following:\n",
      "\n",
      "         $ conda uninstall cupy\n",
      "\n",
      "    2. Install the appropriate CuPy package.\n",
      "       Refer to the Installation Guide for detailed instructions.\n",
      "\n",
      "         https://docs.cupy.dev/en/stable/install.html\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  warnings.warn(f'''\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"]=\"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"]=\"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import sys\n",
    "# PDC-Net path\n",
    "sys.path.append('../DenseMatching/')\n",
    "from easydict import EasyDict as easydic\n",
    "from utils_flow.pixel_wise_mapping import remap_using_flow_fields\n",
    "from model_selection import select_model\n",
    "\n",
    "from skimage import io\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from config import get_life_args, get_raft_args, get_twins_args\n",
    "\n",
    "# LIFE/MS path\n",
    "# sys.path.append('./LIFE')\n",
    "# sys.path.append('./LIFE/core')\n",
    "sys.path.append('./Twins')\n",
    "sys.path.append('./Twins/core')\n",
    "# sys.path.append('./Occ')\n",
    "# sys.path.append('./Occ/core')\n",
    "# sys.path.append('./MultiScale')\n",
    "# sys.path.append('./MultiScale/core')\n",
    "from flow_estimator import Flow_estimator\n",
    "\n",
    "#from core.utils.utils import image_flow_warp\n",
    "#from core.utils.utils import coords_grid\n",
    "\n",
    "# SPSG path\n",
    "sys.path.append('./SPSG')\n",
    "sys.path.append('./SPSG/models')\n",
    "from pathlib import Path \n",
    "import random \n",
    "import matplotlib.cm as cm \n",
    "from SPSG.models.matching import Matching\n",
    "from SPSG.models.utils import (compute_pose_error, compute_epipolar_error,\n",
    "                          estimate_pose, make_matching_plot,\n",
    "                          error_colormap, AverageTimer, pose_auc, read_image,\n",
    "                          rotate_intrinsics, rotate_pose_inplane,\n",
    "                          scale_intrinsics, frame2tensor, plot_image_pair,\n",
    "                          plot_keypoints, plot_matches) \n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# metrics\n",
    "from skimage.metrics import mean_squared_error as mse \n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import datetime\n",
    "# psnr\n",
    "from skimage.util.dtype import dtype_range\n",
    "from skimage._shared.utils import warn, check_shape_equality\n",
    "# ssim\n",
    "from skimage.util.arraycrop import crop\n",
    "from scipy.ndimage import uniform_filter, gaussian_filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_input_images(scene_images, target_images):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    num = len(scene_images)\n",
    "    plt.subplot(221), plt.imshow(scene_images[0]), plt.axis('off')\n",
    "    plt.subplot(222), plt.imshow(target_images[0]), plt.axis('off')\n",
    "    plt.subplot(223), plt.imshow(scene_images[num-1]), plt.axis('off')\n",
    "    plt.subplot(224), plt.imshow(target_images[num-1]), plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend(out, source, scene, blend_type):\n",
    "    intensity = np.linalg.norm(out, axis=2)\n",
    "    mask = (intensity == 0)[:,:,np.newaxis]    \n",
    "    if blend_type == 'light':\n",
    "        result = (out * (1 - mask) + source * mask).astype(np.uint8)\n",
    "    else:\n",
    "        result = (out * (1 - mask) + scene * mask).astype(np.uint8) \n",
    "    return result, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_homography(scene_images, target, source=None, blend_type='scale', detector='SIFT'):\n",
    "    #H, W = 480, 640\n",
    "    #target = cv2.resize(target, (W, H))\n",
    "    print('detector: '+detector)\n",
    "    if detector == 'ORB':\n",
    "        detect = cv2.ORB_create()    \n",
    "    elif detector == 'SIFT':\n",
    "        detect = cv2.SIFT_create()\n",
    "    else:\n",
    "        raise ValueError('detector not implemented')\n",
    "    blends = []\n",
    "    masks = []\n",
    "    for scene in scene_images:\n",
    "        #ori_H, ori_W = scene.shape[:2]\n",
    "        #scene = cv2.resize(scene, (W, H))        \n",
    "        kp1, des1 = detect.detectAndCompute(target, None)\n",
    "        kp2, des2 = detect.detectAndCompute(scene, None)           \n",
    "        if des1 is None or des2 is None:\n",
    "            blends.append(None)   \n",
    "            continue\n",
    "        \n",
    "        if detector == 'ORB':\n",
    "            bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)                \n",
    "            matches = bf.match(des1, des2)\n",
    "            \n",
    "        elif detector == 'SIFT':\n",
    "            FLANN_INDEX_KDTREE = 0\n",
    "            indexParams = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "            searchParams = dict(checks=50)\n",
    "            flann = cv2.FlannBasedMatcher(indexParams, searchParams)    \n",
    "            if len(des1)<2 or len(des2)<2:\n",
    "                blends.append(None)\n",
    "                continue\n",
    "            matches = flann.knnMatch(des1, des2, k=2)\n",
    "            matches = [m for m,n in matches if m.distance < 0.7*n.distance]\n",
    "        else:\n",
    "            raise ValueError('detector {} not implemented'.format(detector))\n",
    "        if len(matches) < 4:\n",
    "            blends.append(None)\n",
    "            continue        \n",
    "        matches = sorted(matches, key=lambda x: x.distance)\n",
    "        #print(len(matches))\n",
    "        #img3 = cv2.drawMatches(target, kp1, scene, kp2, matches[:50], target, flags=2)\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in matches[:50]]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches[:50]]).reshape(-1,1,2)        \n",
    "\n",
    "        M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        if M is None:\n",
    "            blends.append(None)\n",
    "            continue\n",
    "        out = cv2.warpPerspective(target, M, (scene.shape[1], scene.shape[0]))        \n",
    "\n",
    "        blend_i, mask_i = blend(out, source, scene, blend_type)\n",
    "        #blend_i = cv2.resize(blend_i, (ori_W, ori_H))\n",
    "        blends.append(blend_i)\n",
    "        masks.append(mask_i)\n",
    "    return blends, masks\n",
    "    plt.figure(figsize=(20,30))\n",
    "    plt.subplot(131), plt.imshow(target[:,:,::-1]), plt.title('target')\n",
    "    plt.subplot(132), plt.imshow(scene[:,:,::-1]), plt.title('scene')\n",
    "    plt.subplot(133), plt.imshow(blend[:,:,::-1]), plt.title('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_pdc(scene_images, target, flow_estimator, estimate_uncertainty, source=None, blend_type='scale'):            \n",
    "    #H, W = 480, 640\n",
    "    #img1 = cv2.resize(target, (W, H))    \n",
    "    blends = []\n",
    "    masks = []\n",
    "    for scene in scene_images:        \n",
    "        #H_ori, W_ori = scene.shape[:2]                \n",
    "        #img2 = cv2.resize(scene, (W, H))\n",
    "        target = cv2.resize(target, (scene.shape[1], scene.shape[0]))\n",
    "        Is_original = np.ascontiguousarray(target)\n",
    "        It_original = np.ascontiguousarray(scene)\n",
    "        Is_tensor = torch.from_numpy(Is_original).permute(2,0,1).unsqueeze(0)\n",
    "        It_tensor = torch.from_numpy(It_original).permute(2,0,1).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            flow_est, uncertainty_est = flow_estimator.estimate_flow_and_confidence_map(Is_tensor, It_tensor)\n",
    "\n",
    "        flow = flow_est[0].permute([1,2,0]).cpu().detach().numpy()\n",
    "        out = remap_using_flow_fields(Is_original, flow[:,:,0], flow[:,:,1])\n",
    "        #img_warp = cv2.resize(img_warp, (W_ori, H_ori))\n",
    "        \n",
    "        blend_i, mask_i = blend(out, source, scene, blend_type) \n",
    "        #blend_i = cv2.resize(blend_i, (W_ori, H_ori))\n",
    "        blends.append(blend_i)\n",
    "        masks.append(mask_i)\n",
    "    return blends, masks\n",
    "        \n",
    "\n",
    "    '''\n",
    "        confidence_map = uncertainty_est['p_r'].squeeze().detach().cpu().numpy()\n",
    "\n",
    "        plt.figure(figsize=(20,30))\n",
    "        plt.subplot(141), plt.imshow(img1_ori[:,:,::-1]), plt.axis('off')\n",
    "        plt.subplot(142), plt.imshow(img2_ori[:,:,::-1]), plt.axis('off')\n",
    "        plt.subplot(143), plt.imshow(blend[:,:,::-1]), plt.axis('off')\n",
    "        #plt.subplot(144), plt.imshow(confidence_map)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(image_true, image_test, mask=None):\n",
    "    check_shape_equality(image_true, image_test)    \n",
    "\n",
    "    if image_true.dtype != image_test.dtype:\n",
    "        warn(\"Inputs have mismatched dtype. Setting data_range based on \"\n",
    "                \"im_true.\", stacklevel=2)\n",
    "    dmin, dmax = dtype_range[image_true.dtype.type]\n",
    "    true_min, true_max = np.min(image_true), np.max(image_true)\n",
    "    if true_max > dmax or true_min < dmin:\n",
    "        raise ValueError(\n",
    "            \"im_true has intensity values outside the range expected for \"\n",
    "            \"its data type. Please manually specify the data_range\")\n",
    "    if true_min >= 0:\n",
    "        # most common case (255 for uint8, 1 for float)\n",
    "        data_range = dmax\n",
    "    else:\n",
    "        data_range = dmax - dmin\n",
    "    \n",
    "    image_true = image_true.astype(np.float64)\n",
    "    image_test = image_test.astype(np.float64)\n",
    "    if mask is None:                      \n",
    "        err = np.mean((image_true - image_test) ** 2, dtype=np.float64)\n",
    "    else:\n",
    "        mask = 1-mask\n",
    "        cnt = np.count_nonzero(mask) * image_true.shape[2]\n",
    "        sum = np.sum((image_true*mask - image_test*mask)**2)    \n",
    "        err = sum/cnt\n",
    "        '''\n",
    "        plt.figure(facecolor='white')\n",
    "        plt.subplot(121), plt.imshow(image_true.astype(np.uint8)*mask)\n",
    "        plt.subplot(122), plt.imshow(image_test.astype(np.uint8)*mask)\n",
    "        '''\n",
    "    return 10 * np.log10((data_range ** 2) / err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSIM(im1, im2, multichannel=True, mask=None):\n",
    "    check_shape_equality(im1, im2)\n",
    "\n",
    "    if multichannel:\n",
    "        # loop over channels\n",
    "        nch = im1.shape[-1]\n",
    "        mssim = np.empty(nch)\n",
    "        for ch in range(nch):\n",
    "            ch_result = SSIM(im1[..., ch], im2[..., ch], multichannel=False, mask=mask)\n",
    "            mssim[..., ch] = ch_result\n",
    "        mssim = mssim.mean()\n",
    "        return mssim\n",
    "\n",
    "    if im1.dtype != im2.dtype:\n",
    "        warn(\"Inputs have mismatched dtype.  Setting data_range based on im1.dtype.\", stacklevel=2)\n",
    "    dmin, dmax = dtype_range[im1.dtype.type]\n",
    "    data_range = dmax - dmin\n",
    "    \n",
    "    K1 = 0.01\n",
    "    K2 = 0.03\n",
    "    R = data_range\n",
    "    C1 = (K1 * R) ** 2\n",
    "    C2 = (K2 * R) ** 2\n",
    "\n",
    "    # ndimage filters need floating point data\n",
    "    im1 = im1.astype(np.float64)\n",
    "    im2 = im2.astype(np.float64)\n",
    "\n",
    "    if mask is None:\n",
    "        mask = np.zeros_like(im1)\n",
    "        x,y = np.nonzero(1-mask)\n",
    "    else:\n",
    "        x,y,_ = np.nonzero(1-mask)\n",
    "    im1_pixel = im1[x,y]\n",
    "    im2_pixel = im2[x,y]\n",
    "\n",
    "    ux = np.mean(im1_pixel)\n",
    "    uy = np.mean(im2_pixel)\n",
    "    uxy = np.mean(im1_pixel*im2_pixel)\n",
    "    vx = np.var(im1_pixel)\n",
    "    vy = np.var(im2_pixel)\n",
    "    vxy = uxy - ux*uy\n",
    "\n",
    "    ssim = (2*ux*uy+C1)*(2*vxy+C2)/((ux**2+uy**2+C1)*(vx+vy+C2))\n",
    "    return ssim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(id, output_images, masks, save_root, scene_images=None, source=None, blend_type='scale', with_mask=False, save=True):   \n",
    "    if blend_type != 'light' and len(output_images)!=len(scene_images):\n",
    "        raise ValueError('output images should have the same number as scene images')\n",
    "    if save:\n",
    "        save_file = os.path.join(save_root, 'output.txt')\n",
    "    result = {'p':[], 's':[], 'ce':[], 'fail':0}\n",
    "    print('id: {}'.format(str(id).zfill(4)))\n",
    "    if save:\n",
    "        with open(save_file, 'a') as f:\n",
    "            f.write('id: {}\\n'.format(str(id).zfill(4)))\n",
    "\n",
    "    for i, output in enumerate(output_images):\n",
    "        if output is None: \n",
    "            result['p'].append(-1)\n",
    "            result['s'].append(-1)\n",
    "            result['ce'].append(-1)\n",
    "            result['fail'] = result['fail']+1\n",
    "            print('no.{:2d}\\t Failed'.format(i))\n",
    "            if save:\n",
    "                with open(save_file, 'a') as f:\n",
    "                    f.write('no.{:2d}\\t Failed\\n'.format(i))\n",
    "            continue\n",
    "\n",
    "        if blend_type == 'light':\n",
    "            scene = source\n",
    "        else:\n",
    "            scene = scene_images[i]\n",
    "\n",
    "        # print(output.shape[:2], scene.shape[:2])\n",
    "        if not with_mask:\n",
    "            p = psnr(output, scene)\n",
    "            s = ssim(output, scene, multichannel=True)                \n",
    "        else:            \n",
    "            mask = masks[i]\n",
    "            p = PSNR(output, scene, mask=mask)\n",
    "            s = SSIM(output, scene, multichannel=True, mask=mask)                                \n",
    "            #plt.figure(facecolor='white')\n",
    "            #plt.subplot(121), plt.imshow(output*(1-mask)), plt.title('output'), plt.axis('off')\n",
    "            #plt.subplot(122), plt.imshow(scene*(1-mask)), plt.title('scene'), plt.axis('off')\n",
    "            \n",
    "        result['p'].append(round(p, 2))\n",
    "        result['s'].append(round(s, 2))            \n",
    "        #print('no.{:2d}\\t PSNR:{:.2f}\\t SSIM:{:.2f}\\t census error:{:.2f}'.format(i, p, s, ce))\n",
    "        print('no.{:2d}\\t PSNR:{:.2f}\\t SSIM:{:.2f}\\t'.format(i, p, s))\n",
    "        if save:\n",
    "            with open(save_file, 'a') as f:\n",
    "                f.write('no.{:2d}\\t PSNR:{:.2f}\\t SSIM:{:.2f}\\t\\n'.format(i, p, s))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coords_grid(batch, ht, wd):\n",
    "    coords = torch.meshgrid(torch.arange(ht), torch.arange(wd))    \n",
    "    coords = torch.stack(coords[::-1], dim=0).float()     \n",
    "\n",
    "    return coords[None].repeat(batch, 1, 1, 1)\n",
    "    #return np.asarray(coords)\n",
    "    \n",
    "def image_flow_warp(image, scene, flow, padding_mode='zeros'):\n",
    "    '''\n",
    "    Input:\n",
    "        image: HxWx3 numpy\n",
    "        flow: HxWx2 torch.Tensor\n",
    "    Output:\n",
    "        outImg: HxWx3 numpy\n",
    "    '''\n",
    "    image = torch.from_numpy(image)\n",
    "    if image.ndim == 2:\n",
    "        image = image[None].permute([1,2,0])\n",
    "    H, W, _ = image.shape\n",
    "    coords = coords_grid(1, H, W).cuda().float().contiguous()\n",
    "    flow = flow[None].repeat(1, 1, 1, 1).permute([0, 3, 1, 2]).float().contiguous()    \n",
    "    grid = (flow + coords).permute([0, 2, 3, 1]).contiguous()   # (1, H, W, 2)  \n",
    "    \n",
    "    grid[:, :, :, 0] = (grid[:, :, :, 0] * 2 - W + 1) / (W - 1)\n",
    "    grid[:, :, :, 1] = (grid[:, :, :, 1] * 2 - H + 1) / (H - 1)    \n",
    "    image = image[None].permute([0, 3, 1, 2]).cuda().float()\n",
    "    \n",
    "    outImg = F.grid_sample(image, grid, padding_mode=padding_mode, align_corners=False)[0].cpu().numpy().transpose([1, 2, 0])\n",
    "    return outImg.astype(np.uint8)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_life(scene_images, target, estimator, source=None, blend_type='scale', warp='grid_sample'):    \n",
    "    #H, W = 480, 640    \n",
    "    blends = []\n",
    "    masks = []\n",
    "    for scene in scene_images:        \n",
    "        #ori_H, ori_W = scene.shape[:2]\n",
    "        #scene = cv2.resize(scene, (W, H))\n",
    "        target = cv2.resize(target, (scene.shape[1], scene.shape[0]))\n",
    "        flow = estimator.estimate(scene, target)           \n",
    "\n",
    "        \n",
    "        if warp == 'grid_sample':\n",
    "            out = image_flow_warp(target, scene, flow[0].permute([1,2,0]))            \n",
    "        elif warp == 'homography':\n",
    "        # RANSAC homography\n",
    "            flow = flow[0].permute([1,2,0])\n",
    "            image = target\n",
    "            img = image\n",
    "            sce = scene\n",
    "            image = torch.from_numpy(image)\n",
    "            if image.ndim == 2:\n",
    "                image = image[None].permute([1,2,0])\n",
    "            H, W, _ = image.shape\n",
    "            coords = coords_grid(1, H, W).cuda().float().contiguous()\n",
    "            flow = flow[None].repeat(1, 1, 1, 1).permute([0, 3, 1, 2]).float().contiguous()    \n",
    "            grid = (flow + coords).permute([0, 2, 3, 1]).contiguous()   # (1, H, W, 2)\n",
    "            grid = grid[0].cpu()\n",
    "            src_pts = []\n",
    "            dst_pts = []\n",
    "            for y in range(H):\n",
    "                for x in range(W):\n",
    "                    if grid[y,x,0]>=0 and grid[y,x,0]<W and grid[y,x,1]>=0 and grid[y,x,1]<H:\n",
    "                        src_pts.append((grid[y,x,0], grid[y,x,1]))\n",
    "                        dst_pts.append((x, y))                        \n",
    "            src_pts = np.float32(src_pts)\n",
    "            dst_pts = np.float32(dst_pts)\n",
    "            '''\n",
    "            num = len(src_pts)\n",
    "            for idx in range(num):\n",
    "                print(src_pts[idx], dst_pts[idx])\n",
    "                cv2.circle(img, (int(src_pts[idx][0]), int(src_pts[idx][1])), 1, (255, 0, 0))\n",
    "                cv2.circle(sce, (int(dst_pts[idx][0]), int(dst_pts[idx][1])), 1, (255, 0, 0))\n",
    "            plt.figure(facecolor='white')\n",
    "            plt.subplot(1,2,1), plt.imshow(img)\n",
    "            plt.subplot(1,2,2), plt.imshow(sce)\n",
    "            plt.show()\n",
    "            '''\n",
    "            M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "            if M is None:\n",
    "                blends.append(None)\n",
    "                continue\n",
    "            out = cv2.warpPerspective(target, M, (scene.shape[1], scene.shape[0]))        \n",
    "\n",
    "        blend_i, mask_i = blend(out, source, scene, blend_type)\n",
    "        blends.append(blend_i)\n",
    "        masks.append(mask_i)\n",
    "    return blends, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_SPSG(scene_images, target, matching=None, source=None, blend_type='scale', save_root=None):\n",
    "    blends = []\n",
    "    masks = []\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    for idx, scene in enumerate(scene_images):\n",
    "        target = cv2.resize(target, (scene.shape[1], scene.shape[0]))\n",
    "        target_gray = cv2.cvtColor(target, cv2.COLOR_BGR2GRAY)\n",
    "        scene_gray = cv2.cvtColor(scene, cv2.COLOR_BGR2GRAY)\n",
    "        inp0 = frame2tensor(target_gray, device=device)\n",
    "        inp1 = frame2tensor(scene_gray, device=device)        \n",
    "        pred = matching({'image0': inp0, 'image1': inp1})\n",
    "        pred = {k: v[0].cpu().numpy() for k, v in pred.items()}\n",
    "        kpts0, kpts1 = pred['keypoints0'], pred['keypoints1']\n",
    "        matches, conf = pred['matches0'], pred['matching_scores0']\n",
    "\n",
    "        valid = matches > -1          \n",
    "        mkpts0 = kpts0[valid]\n",
    "        mkpts1 = kpts1[matches[valid]] \n",
    "        mconf = conf[valid]\n",
    "        \n",
    "        # plot_image_pair([target, scene])        \n",
    "        # plot_keypoints(kpts0, kpts1, color='k', ps=4)\n",
    "        # plot_keypoints(kpts0, kpts1, color='w', ps=2)\n",
    "        # plot_matches(mkpts0, mkpts1, color='r')\n",
    "        # plt.show()\n",
    "        # plt.savefig(os.path.join(save_root, 'SPSG_match_'+str(idx)+'.jpg'), bbox_inches='tight', pad_inches=0)\n",
    "        \n",
    "        valid = mconf > 0.5\n",
    "        mkpts0 = mkpts0[valid]\n",
    "        mkpts1 = mkpts1[valid]\n",
    "        \n",
    "        if np.count_nonzero(valid) < 4:\n",
    "            blends.append(None)\n",
    "            masks.append(None)\n",
    "            continue\n",
    "        \n",
    "        src_pts = np.float32(mkpts0).reshape(-1,1,2)\n",
    "        dst_pts = np.float32(mkpts1).reshape(-1,1,2)\n",
    "        M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        if M is None:\n",
    "            blends.append(None)\n",
    "            masks.append(None)\n",
    "            continue\n",
    "        out = cv2.warpPerspective(target, M, (scene.shape[1], scene.shape[0]))        \n",
    "\n",
    "        blend_i, mask_i = blend(out, source, scene, blend_type)\n",
    "        #blend_i = cv2.resize(blend_i, (ori_W, ori_H))\n",
    "        blends.append(blend_i)\n",
    "        masks.append(mask_i)\n",
    "        \n",
    "        \n",
    "    return blends, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(id, \n",
    "         scene_images, \n",
    "         target,           \n",
    "         save_root, \n",
    "         blend_method='life',\n",
    "         blend_type='scale', \n",
    "         estimator=None, \n",
    "         flow_estimator=None, \n",
    "         estimate_uncertainty=None, \n",
    "         matching=None,\n",
    "         source=None,\n",
    "         detector='SIFT',\n",
    "         with_mask = False,\n",
    "         draw = True,\n",
    "         save = True,\n",
    "         warp = 'grid_sample'):   \n",
    "    '''\n",
    "    Args:\n",
    "        @id: (int) target image id, for logging\n",
    "        @scene_images: (list) test scene images\n",
    "        @target: (array) target image\n",
    "        @save_root: (string) \n",
    "        @blend_method: (string, 'life') ['life', 'homography', 'pdc']\n",
    "        @blend_type: (string, 'scale') ['scale', 'light', 'viewpoint']\n",
    "        @estimator: model to estimate when blend_method=='life'\n",
    "        @flow_estimator: model to estimate when blend_method=='pdc'\n",
    "        @estimate_uncertainty: check result uncertainty when blend_method=='pdc'\n",
    "        @source: source image to calculate metrics when blend_type=='lighting'\n",
    "        @detector: (string, 'SIFT) ['SIFT', 'ORB'] detector used in homography\n",
    "        @with_mask: (bool) calculate metrics with or without mask\n",
    "        @draw: (bool) show results or not\n",
    "        @save: (bool) save results or not\n",
    "        @warp: (string,'grid_sample') ['grid_sample', 'homography'] warp method for LIFE model\n",
    "    '''\n",
    "    if blend_method in ['life', 'raft', 'biraft', 'ms', 'twins', 'occ']:\n",
    "        if estimator is None:\n",
    "            raise ValueError('estimator not set')\n",
    "        print('warp method: '+warp)\n",
    "        out, mask = blend_life(scene_images, target, estimator=estimator, source=source, blend_type=blend_type, warp=warp)\n",
    "    elif blend_method == 'homography':        \n",
    "        out, mask = blend_homography(scene_images, target, source=source, blend_type=blend_type, detector=detector)\n",
    "    elif blend_method == 'pdc':\n",
    "        if flow_estimator is None:\n",
    "            raise ValueError('estimator not set')\n",
    "        out, mask = blend_pdc(scene_images, target, flow_estimator=flow_estimator, estimate_uncertainty=estimate_uncertainty, source=source, blend_type=blend_type)\n",
    "    elif blend_method == 'SPSG':\n",
    "        save_root = os.path.join(save_root, str(id).zfill(4))\n",
    "        if save and not os.path.exists(save_root):\n",
    "            os.makedirs(save_root)\n",
    "        out, mask = blend_SPSG(scene_images, target, matching=matching, source=source, blend_type=blend_type, save_root=save_root)\n",
    "    else:\n",
    "        raise ValueError('blend method has not been implemented')\n",
    "\n",
    "        \n",
    "    if blend_type == 'light':\n",
    "        result = metrics(id, out, mask, save_root=save_root, source=source, blend_type=blend_type, with_mask=with_mask, save=save)\n",
    "    else:\n",
    "        result = metrics(id, out, mask, save_root=save_root, scene_images =scene_images, blend_type=blend_type, with_mask=with_mask, save=save)\n",
    "    \n",
    "    #if not with_mask and draw:\n",
    "    if draw: \n",
    "        save_root = os.path.join(save_root, str(id).zfill(4))\n",
    "        if save and not os.path.exists(save_root):\n",
    "            os.makedirs(save_root)\n",
    "        for i in range(len(scene_images)): \n",
    "            if out[i] is None:\n",
    "                continue\n",
    "            title = 'PSNR: '+str(result['p'][i])+' SSIM: '+str(result['s'][i])\n",
    "            #plt.figure(figsize=(10,15), facecolor='white')       \n",
    "            plt.figure(facecolor='white')\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(target), plt.title('target '+str(id).zfill(4)), plt.axis('off')        \n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(scene_images[i]), plt.title('scene '+str(i).zfill(4)), plt.axis('off')        \n",
    "            plt.subplot(1, 3, 3)\n",
    "            if not with_mask:\n",
    "                plt.imshow(out[i]), plt.title(title), plt.axis('off')\n",
    "            else:\n",
    "                plt.imshow(out[i]*(1-mask[i])), plt.title(title), plt.axis('off')\n",
    "            if save: \n",
    "                #plt.figure(facecolor='white')\n",
    "                #plt.imshow(out[i]*(1-mask[i])), plt.title(title), plt.axis('off')\n",
    "                plt.savefig(os.path.join(save_root,str(i)+'.png'), dpi=200, bbox_inches='tight')\n",
    "                #io.imsave(os.path.join(save_root, str(i)+'_'+title+'.png'), cv2.resize(out[i],None,fx=0.25,fy=0.25))\n",
    "            plt.close()\n",
    "            \n",
    "    return (out, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(root = './assets/',\n",
    "        blend_type = 'scale',\n",
    "        blend_method = 'life', \n",
    "        img_num = 5, \n",
    "        start_img_id = 0,\n",
    "        start_scene_id = 0,\n",
    "        scn_num = 10,\n",
    "        source_id = -1,\n",
    "        H = 480,\n",
    "        W = 640,\n",
    "        with_mask = False,\n",
    "        draw = True,\n",
    "        save = True,\n",
    "        detector=\"SIFT\",\n",
    "        multisample=True,\n",
    "        folder=\"\",\n",
    "        warp='grid_sample'):\n",
    "    '''\n",
    "    Args:\n",
    "        @root: (string, './assets/') image data root\n",
    "        @blend_type: (string, 'scale) ['scale', 'light', 'viewpoint', 'deformation', 'occlusion']\n",
    "        @blend_method: (string, 'life') ['life', 'homography', 'pdc']\n",
    "        @img_num: (int, 5) number of test images\n",
    "        @start_img_id: (int, 0) test from image with id=start_img_id\n",
    "        @start_scene_id: (int, 0) test from scene image with id=start_scene_id\n",
    "        @scn_num: (int, 10) number of scene images per test image\n",
    "        @source_id: if blend_type=='light', source id should be specified for metrics calculation\n",
    "        @(W, H): resize images\n",
    "        @with_mask: caculate PSNR/SSIM with or without mask\n",
    "        @draw: (bool)\n",
    "        @save: (bool)\n",
    "        @detector: (string, 'SIFT') ['SIFT', 'ORB']\n",
    "        @multisample: (bool, True) if False(not one of blend_type), specify scene images folder\n",
    "        @warp: (string, 'grid_sample') ['grid_sample', 'homography'] warp method for LIFE model\n",
    "    Ouput:\n",
    "        folder '{blend_method}_output_{time}' with output images and output.txt(metrics) will be created under folder {blend_type}\n",
    "    '''\n",
    "    # path setting\n",
    "    if blend_type == 'light':\n",
    "        if source_id == -1:\n",
    "            raise FileExistsError('no source image id specified.')    \n",
    "    if multisample:\n",
    "        scene_root = os.path.join(root, blend_type)\n",
    "    else:\n",
    "        if folder==\"\":\n",
    "            raise FileNotFoundError(\"input folder name\")\n",
    "        scene_root = os.path.join(root, folder) \n",
    "    time = datetime.datetime.now()\n",
    "    suffix = datetime.datetime.strftime(time, '%m%d%H%M')\n",
    "    if not with_mask:\n",
    "        save_root = os.path.join(scene_root, blend_method+'_output_'+suffix)\n",
    "    else:\n",
    "        save_root = os.path.join(scene_root, blend_method+'_output_mask_'+suffix)\n",
    "    if save and not os.path.exists(save_root):\n",
    "        os.makedirs(save_root)\n",
    "\n",
    "    # data loading\n",
    "    if H > W:\n",
    "        H, W = W, H\n",
    "    scene_images = []\n",
    "    target_images = []    \n",
    "    for id in range(img_num):\n",
    "        id = id + start_img_id\n",
    "        scene_image = []\n",
    "        for i in range(start_scene_id, scn_num):\n",
    "            scene_path = os.path.join(scene_root, str(id).zfill(4) + \"_\" + blend_type + \"_\"+str(i)+\".jpg\")\n",
    "            scene = io.imread(scene_path)\n",
    "            if scene.shape[0] > scene.shape[1]: # H > W\n",
    "                scene = cv2.resize(scene, (H, W))\n",
    "            else:\n",
    "                scene = cv2.resize(scene, (W, H))\n",
    "            scene_image.append(scene)\n",
    "        scene_images.append(scene_image)\n",
    "\n",
    "        target_path = os.path.join(root, str(id).zfill(4) + \".jpg\")\n",
    "        target_image = io.imread(target_path)\n",
    "        if target_image.shape[0] > target_image.shape[1]: # H > W\n",
    "            target_image = cv2.resize(target_image, (H, W))\n",
    "        else:\n",
    "            target_image = cv2.resize(target_image, (W, H))        \n",
    "        target_images.append(target_image)\n",
    "    total = len(scene_images)*len(scene_images[0])\n",
    "    print('input {}x{} scene images'.format(len(scene_images), len(scene_images[0])))\n",
    "    print('input {} target images'.format(len(target_images)))\n",
    "    # show_input_images(scene_images, target_images)\n",
    "\n",
    "    # model loading\n",
    "    print('blend method: ', blend_method)\n",
    "    if blend_method in ['life', 'raft', 'biraft', 'ms', 'occ', 'twins']:            \n",
    "        if blend_method == 'life':\n",
    "            args = get_life_args()  \n",
    "        elif blend_method == 'twins':\n",
    "            args = get_twins_args()\n",
    "            args.fnet = 'twins'\n",
    "            args.model = './model/twins-twostage.pth'\n",
    "            args.twoscale = True\n",
    "            # args.model = './model/twins-onestage.pth'\n",
    "            # args.twoscale = False\n",
    "            # args.dim_corr_all = 192\n",
    "        else:\n",
    "            args = get_raft_args()\n",
    "            if blend_method == 'biraft':\n",
    "                args.model = './model/biRAFT_latest.pth'\n",
    "            elif blend_method == 'ms':\n",
    "                args.model = './model/MultiScale_latest.pth'\n",
    "            elif blend_method=='occ':\n",
    "                args.model = \"./model/RAFT_twins_bs12_ep20.pth\"                \n",
    "        for k, v in vars(args).items():\n",
    "            print(k,'=',v)\n",
    "        #estimator = Flow_estimator(args, method=blend_method)\n",
    "        estimator = Flow_estimator(args)\n",
    "    elif blend_method == 'pdc':\n",
    "        args = easydic({\n",
    "            'model': 'PDCNet',\n",
    "            'pre_trained_model_type': 'megadepth',\n",
    "            'path_to_pre_trained_models': '/home/weihong/work/Optical_Flow/DenseMatching/pre_trained_models',\n",
    "            'local_optim_iter': 7,\n",
    "            'optim_iter': 3,\n",
    "            'network_type': None\n",
    "        })\n",
    "        flow_estimator, estimate_uncertainty = select_model(\n",
    "            args.model, \n",
    "            args.pre_trained_model_type, \n",
    "            args,\n",
    "            args.optim_iter, \n",
    "            args.local_optim_iter,\n",
    "            path_to_pre_trained_models=args.path_to_pre_trained_models)\n",
    "\n",
    "    elif blend_method == 'SPSG':\n",
    "        opt = easydic({\n",
    "            'nms_radius': 4,\n",
    "            'keypoint_threshold': 0.005,\n",
    "            'max_keypoints': 1024,\n",
    "            'superglue': 'indoor',\n",
    "            'sinkhorn_iterations': 20,\n",
    "            'match_threshold': 0.2,\n",
    "        })\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print('Running inference on device \\\"{}\\\"'.format(device))\n",
    "        config = {\n",
    "            'superpoint': {\n",
    "                'nms_radius': opt.nms_radius,\n",
    "                'keypoint_threshold': opt.keypoint_threshold,\n",
    "                'max_keypoints': opt.max_keypoints\n",
    "            },\n",
    "            'superglue': {\n",
    "                'weights': opt.superglue,\n",
    "                'sinkhorn_iterations': opt.sinkhorn_iterations,\n",
    "                'match_threshold': opt.match_threshold,\n",
    "            }\n",
    "        }\n",
    "        matching = Matching(config).eval().to(device)\n",
    "            \n",
    "    ID = []\n",
    "    #out_images = []\n",
    "    #results = []\n",
    "    p = []\n",
    "    s = []\n",
    "    fail = 0\n",
    "    for id in range(img_num):\n",
    "        scene = scene_images[id]\n",
    "        target = target_images[id]\n",
    "        source = scene[source_id]  \n",
    "        if blend_method in ['life', 'raft', 'biraft', 'ms', 'twins', 'occ']:\n",
    "            out, result = eval(id, scene, target, blend_method=blend_method, save_root=save_root, source=source, blend_type=blend_type, estimator=estimator, with_mask=with_mask, draw=draw, save=save, warp=warp)\n",
    "        elif blend_method == 'pdc':\n",
    "            out, result = eval(id, scene, target, blend_method=blend_method, save_root=save_root, source=source, blend_type=blend_type, flow_estimator=flow_estimator, estimate_uncertainty=estimate_uncertainty, with_mask=with_mask, draw=draw, save=save)\n",
    "        elif blend_method == 'homography':\n",
    "            out, result = eval(id, scene, target, blend_method=blend_method, save_root=save_root, source=source, blend_type=blend_type, with_mask=with_mask, detector=detector, draw=draw, save=save)\n",
    "        elif blend_method == 'SPSG':\n",
    "            out, result = eval(id, scene, target, blend_method=blend_method, save_root=save_root, source=source, blend_type=blend_type, matching=matching, with_mask=with_mask, draw=draw, save=save)\n",
    "        else:\n",
    "            raise ValueError('blend method not inplemented')\n",
    "        #out_images.append(out)\n",
    "        #results.append(result)\n",
    "        #ID.append(str(id).zfill(4))\n",
    "        \n",
    "        # p.append(result['p'])\n",
    "        # s.append(result['s'])\n",
    "        p.append([result['p'][i] for i in range(len(result['p'])) if result['p'][i]!=-1])\n",
    "        s.append([result['s'][i] for i in range(len(result['s'])) if result['s'][i]!=-1])\n",
    "        fail = fail + result['fail']\n",
    "    \n",
    "    # p_array = np.asarray(p).flatten()\n",
    "    # s_array = np.asarray(s).flatten()\n",
    "    p_array = np.asarray([item for sub in p for item in sub])\n",
    "    s_array = np.asarray([item for sub in s for item in sub])\n",
    "    #print(p_array)\n",
    "    print(blend_method+'\\t PSNR: {:.2f}/{:.2f}\\t SSIM: {:.2f}/{:.2f}\\t fail: {:.2f}%({}/{})'\n",
    "        .format(np.mean(p_array), \n",
    "                np.median(p_array),\n",
    "                np.mean(s_array), \n",
    "                np.median(s_array),\n",
    "                fail*1.0/total*100,\n",
    "                fail, total))\n",
    "    \n",
    "    #draw_result(ID, out_images, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input 10x10 scene images\n",
      "input 10 target images\n",
      "blend method:  twins\n",
      "mixed_precision = True\n",
      "small = False\n",
      "iters = 12\n",
      "dim_corr = 192\n",
      "dim_corr_coarse = 64\n",
      "dim_corr_all = 256\n",
      "model = ./model/twins-twostage.pth\n",
      "fnet = twins\n",
      "twoscale = True\n",
      "warp method: grid_sample\n",
      "id: 0000\n",
      "no. 0\t PSNR:17.94\t SSIM:0.86\t\n",
      "no. 1\t PSNR:16.09\t SSIM:0.81\t\n",
      "no. 2\t PSNR:14.76\t SSIM:0.71\t\n",
      "no. 3\t PSNR:12.04\t SSIM:0.46\t\n",
      "no. 4\t PSNR:16.45\t SSIM:0.82\t\n",
      "no. 5\t PSNR:15.63\t SSIM:0.78\t\n",
      "no. 6\t PSNR:13.66\t SSIM:0.61\t\n",
      "no. 7\t PSNR:14.57\t SSIM:0.70\t\n",
      "no. 8\t PSNR:14.11\t SSIM:0.67\t\n",
      "no. 9\t PSNR:16.03\t SSIM:0.79\t\n",
      "warp method: grid_sample\n",
      "id: 0001\n",
      "no. 0\t PSNR:13.32\t SSIM:0.83\t\n",
      "no. 1\t PSNR:13.06\t SSIM:0.82\t\n",
      "no. 2\t PSNR:14.83\t SSIM:0.81\t\n",
      "no. 3\t PSNR:13.10\t SSIM:0.67\t\n",
      "no. 4\t PSNR:13.84\t SSIM:0.81\t\n",
      "no. 5\t PSNR:14.27\t SSIM:0.82\t\n",
      "no. 6\t PSNR:12.28\t SSIM:0.62\t\n",
      "no. 7\t PSNR:15.03\t SSIM:0.83\t\n",
      "no. 8\t PSNR:14.21\t SSIM:0.79\t\n",
      "no. 9\t PSNR:13.39\t SSIM:0.75\t\n",
      "warp method: grid_sample\n",
      "id: 0002\n",
      "no. 0\t PSNR:19.66\t SSIM:0.87\t\n",
      "no. 1\t PSNR:16.49\t SSIM:0.74\t\n",
      "no. 2\t PSNR:15.60\t SSIM:0.64\t\n",
      "no. 3\t PSNR:18.39\t SSIM:0.79\t\n",
      "no. 4\t PSNR:17.61\t SSIM:0.76\t\n",
      "no. 5\t PSNR:15.90\t SSIM:0.66\t\n",
      "no. 6\t PSNR:17.01\t SSIM:0.72\t\n",
      "no. 7\t PSNR:14.60\t SSIM:0.54\t\n",
      "no. 8\t PSNR:15.41\t SSIM:0.61\t\n",
      "no. 9\t PSNR:17.60\t SSIM:0.77\t\n",
      "warp method: grid_sample\n",
      "id: 0003\n",
      "no. 0\t PSNR:19.46\t SSIM:0.80\t\n",
      "no. 1\t PSNR:13.38\t SSIM:0.34\t\n",
      "no. 2\t PSNR:14.01\t SSIM:0.41\t\n",
      "no. 3\t PSNR:16.55\t SSIM:0.62\t\n",
      "no. 4\t PSNR:18.55\t SSIM:0.70\t\n",
      "no. 5\t PSNR:16.32\t SSIM:0.57\t\n",
      "no. 6\t PSNR:14.23\t SSIM:0.45\t\n",
      "no. 7\t PSNR:16.28\t SSIM:0.54\t\n",
      "no. 8\t PSNR:15.98\t SSIM:0.57\t\n",
      "no. 9\t PSNR:15.08\t SSIM:0.50\t\n",
      "warp method: grid_sample\n",
      "id: 0004\n",
      "no. 0\t PSNR:16.51\t SSIM:0.88\t\n",
      "no. 1\t PSNR:12.60\t SSIM:0.68\t\n",
      "no. 2\t PSNR:13.25\t SSIM:0.67\t\n",
      "no. 3\t PSNR:14.73\t SSIM:0.81\t\n",
      "no. 4\t PSNR:13.12\t SSIM:0.74\t\n",
      "no. 5\t PSNR:11.66\t SSIM:0.60\t\n",
      "no. 6\t PSNR:13.45\t SSIM:0.67\t\n",
      "no. 7\t PSNR:14.50\t SSIM:0.73\t\n",
      "no. 8\t PSNR:12.99\t SSIM:0.61\t\n",
      "no. 9\t PSNR:15.64\t SSIM:0.82\t\n",
      "warp method: grid_sample\n",
      "id: 0005\n",
      "no. 0\t PSNR:16.49\t SSIM:0.87\t\n",
      "no. 1\t PSNR:15.26\t SSIM:0.82\t\n",
      "no. 2\t PSNR:11.99\t SSIM:0.63\t\n",
      "no. 3\t PSNR:10.91\t SSIM:0.52\t\n",
      "no. 4\t PSNR:15.55\t SSIM:0.83\t\n",
      "no. 5\t PSNR:12.22\t SSIM:0.63\t\n",
      "no. 6\t PSNR:10.79\t SSIM:0.55\t\n",
      "no. 7\t PSNR:12.08\t SSIM:0.66\t\n",
      "no. 8\t PSNR:11.29\t SSIM:0.55\t\n",
      "no. 9\t PSNR:9.12\t SSIM:0.33\t\n",
      "warp method: grid_sample\n",
      "id: 0006\n",
      "no. 0\t PSNR:17.16\t SSIM:0.82\t\n",
      "no. 1\t PSNR:11.69\t SSIM:0.44\t\n",
      "no. 2\t PSNR:9.14\t SSIM:0.22\t\n",
      "no. 3\t PSNR:10.75\t SSIM:0.39\t\n",
      "no. 4\t PSNR:14.19\t SSIM:0.63\t\n",
      "no. 5\t PSNR:9.72\t SSIM:0.20\t\n",
      "no. 6\t PSNR:10.39\t SSIM:0.42\t\n",
      "no. 7\t PSNR:9.75\t SSIM:0.32\t\n",
      "no. 8\t PSNR:10.67\t SSIM:0.35\t\n",
      "no. 9\t PSNR:7.65\t SSIM:0.01\t\n",
      "warp method: grid_sample\n",
      "id: 0007\n",
      "no. 0\t PSNR:13.34\t SSIM:0.70\t\n",
      "no. 1\t PSNR:12.15\t SSIM:0.57\t\n",
      "no. 2\t PSNR:13.34\t SSIM:0.68\t\n",
      "no. 3\t PSNR:11.71\t SSIM:0.53\t\n",
      "no. 4\t PSNR:14.21\t SSIM:0.72\t\n",
      "no. 5\t PSNR:12.17\t SSIM:0.57\t\n",
      "no. 6\t PSNR:13.30\t SSIM:0.68\t\n",
      "no. 7\t PSNR:13.59\t SSIM:0.67\t\n",
      "no. 8\t PSNR:13.20\t SSIM:0.66\t\n",
      "no. 9\t PSNR:10.70\t SSIM:0.38\t\n",
      "warp method: grid_sample\n",
      "id: 0008\n",
      "no. 0\t PSNR:15.51\t SSIM:0.64\t\n",
      "no. 1\t PSNR:14.83\t SSIM:0.57\t\n",
      "no. 2\t PSNR:13.12\t SSIM:0.33\t\n",
      "no. 3\t PSNR:12.14\t SSIM:0.17\t\n",
      "no. 4\t PSNR:13.93\t SSIM:0.33\t\n",
      "no. 5\t PSNR:14.38\t SSIM:0.51\t\n",
      "no. 6\t PSNR:15.16\t SSIM:0.59\t\n",
      "no. 7\t PSNR:14.73\t SSIM:0.53\t\n",
      "no. 8\t PSNR:13.11\t SSIM:0.45\t\n",
      "no. 9\t PSNR:10.55\t SSIM:0.04\t\n",
      "warp method: grid_sample\n",
      "id: 0009\n",
      "no. 0\t PSNR:12.54\t SSIM:0.52\t\n",
      "no. 1\t PSNR:11.85\t SSIM:0.42\t\n",
      "no. 2\t PSNR:11.62\t SSIM:0.34\t\n",
      "no. 3\t PSNR:13.90\t SSIM:0.67\t\n",
      "no. 4\t PSNR:13.80\t SSIM:0.63\t\n",
      "no. 5\t PSNR:13.79\t SSIM:0.59\t\n",
      "no. 6\t PSNR:13.88\t SSIM:0.62\t\n",
      "no. 7\t PSNR:13.47\t SSIM:0.59\t\n",
      "no. 8\t PSNR:14.08\t SSIM:0.64\t\n",
      "no. 9\t PSNR:10.59\t SSIM:0.18\t\n",
      "twins\t PSNR: 13.87/13.86\t SSIM: 0.60/0.63\t fail: 0.00%(0/100)\n"
     ]
    }
   ],
   "source": [
    "''' 数据集格式\n",
    "|-deformation (scene images)\n",
    "    |-0000_deformation_0.jpg\n",
    "    |-0000_deformation_1.jpg\n",
    "    |-...\n",
    "    |-0001_deformation_0.jpg\n",
    "    |-...\n",
    "|-light\n",
    "|-occlusion\n",
    "|-scale\n",
    "|-viewpoint\n",
    "|-0000.jpg (target image)\n",
    "\n",
    "|-0001.jpg\n",
    "|-...\n",
    "'''\n",
    "# life / multiscale / twins 记得改模型路径！！！\n",
    "# sift\n",
    "# run(blend_type='deformation', blend_method='homography', warp='grid_sample', img_num=10, scn_num=10, source_id=1, with_mask=True, multisample=True, folder=\"minions\", start_img_id=0, start_scene_id = 0, draw=False, save=False, detector=\"SIFT\")\n",
    "# SPSG\n",
    "# run(blend_type='deformation', blend_method='SPSG', warp='grid_sample', img_num=10, scn_num=10, source_id=1, with_mask=True, multisample=True, folder=\"minions\", start_img_id=0, start_scene_id = 0, draw=False, save=False, detector=\"SIFT\")\n",
    "run(blend_type='deformation', blend_method='twins', warp='grid_sample', img_num=10, scn_num=10, source_id=1, with_mask=True, multisample=True, folder=\"minions\", start_img_id=0, start_scene_id = 0, draw=False, save=False, detector=\"SIFT\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24d476ac703b729f04d8ac5d768e8057e3dd62c7be786439cca60b67954f1529"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
