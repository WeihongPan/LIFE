{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"]=\"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"]=\"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import sys\n",
    "# PDC-Net path\n",
    "sys.path.append('../DenseMatching/')\n",
    "from easydict import EasyDict as easydic\n",
    "from utils_flow.pixel_wise_mapping import remap_using_flow_fields\n",
    "from model_selection import select_model\n",
    "\n",
    "from skimage import io\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "\n",
    "# LIFE path\n",
    "sys.path.append('./LIFE2')\n",
    "sys.path.append('./LIFE2/core')\n",
    "# sys.path.append('./RAFT')\n",
    "# sys.path.append('./RAFT/core')\n",
    "# sys.path.append('./Twins')\n",
    "# sys.path.append('./Twins/core')\n",
    "# sys.path.append('./Twins-new')\n",
    "# sys.path.append('./Twins-new/core')\n",
    "# sys.path.append('./Occ')\n",
    "# sys.path.append('./Occ/core')\n",
    "# sys.path.append('./MultiScale')\n",
    "# sys.path.append('./MultiScale/core')\n",
    "from flow_estimator import Flow_estimator\n",
    "if './Twins-new' in sys.path:\n",
    "    from core.utils.forward_warp import ForwardWarp\n",
    "# from core.utils.utils import image_flow_warp\n",
    "# from core.utils.utils import coords_grid\n",
    "from config import get_life_args, get_raft_args, get_twins_args\n",
    "\n",
    "# SPSG path\n",
    "sys.path.append('./SPSG')\n",
    "sys.path.append('./SPSG/models')\n",
    "from pathlib import Path \n",
    "import random \n",
    "import matplotlib.cm as cm \n",
    "from SPSG.models.matching import Matching\n",
    "from SPSG.models.utils import (compute_pose_error, compute_epipolar_error,\n",
    "                          estimate_pose, make_matching_plot,\n",
    "                          error_colormap, AverageTimer, pose_auc, read_image,\n",
    "                          rotate_intrinsics, rotate_pose_inplane,\n",
    "                          scale_intrinsics, frame2tensor, plot_image_pair,\n",
    "                          plot_keypoints, plot_matches) \n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# metrics\n",
    "from skimage.metrics import mean_squared_error as mse \n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import datetime\n",
    "# psnr\n",
    "from skimage.util.dtype import dtype_range\n",
    "from skimage._shared.utils import warn, check_shape_equality\n",
    "# ssim\n",
    "from skimage.util.arraycrop import crop\n",
    "from scipy.ndimage import uniform_filter, gaussian_filter\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageColor\n",
    "import plotly.graph_objects as go\n",
    "import plotly.colors\n",
    "\n",
    "def get_color(colorscale_name, loc):\n",
    "    from _plotly_utils.basevalidators import ColorscaleValidator\n",
    "    # first parameter: Name of the property being validated\n",
    "    # second parameter: a string, doesn't really matter in our use case\n",
    "    cv = ColorscaleValidator(\"colorscale\", \"\")\n",
    "    # colorscale will be a list of lists: [[loc1, \"rgb1\"], [loc2, \"rgb2\"], ...]\n",
    "    colorscale = cv.validate_coerce(colorscale_name)\n",
    "\n",
    "    if hasattr(loc, \"__iter__\"):\n",
    "        intermediate_colors = [get_continuous_color(colorscale, x) for x in loc]\n",
    "        return intermediate_colors\n",
    "    return get_continuous_color(colorscale, loc)\n",
    "\n",
    "\n",
    "def get_continuous_color(colorscale, intermed):\n",
    "    \"\"\"\n",
    "    Plotly continuous colorscales assign colors to the range [0, 1]. This function computes the intermediate\n",
    "    color for any value in that range.\n",
    "    Plotly doesn't make the colorscales directly accessible in a common format.\n",
    "    Some are ready to use:\n",
    "        colorscale = plotly.colors.PLOTLY_SCALES[\"Greens\"]\n",
    "    Others are just swatches that need to be constructed into a colorscale:\n",
    "        viridis_colors, scale = plotly.colors.convert_colors_to_same_type(plotly.colors.sequential.Viridis)\n",
    "        colorscale = plotly.colors.make_colorscale(viridis_colors, scale=scale)\n",
    "    :param colorscale: A plotly continuous colorscale defined with RGB string colors.\n",
    "    :param intermed: value in the range [0, 1]\n",
    "    :return: color in rgb string format\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    if len(colorscale) < 1:\n",
    "        raise ValueError(\"colorscale must have at least one color\")\n",
    "\n",
    "    hex_to_rgb = lambda c: \"rgb\" + str(ImageColor.getcolor(c, \"RGB\"))\n",
    "\n",
    "    if intermed <= 0 or len(colorscale) == 1:\n",
    "        c = colorscale[0][1]\n",
    "        return c if c[0] != \"#\" else hex_to_rgb(c)\n",
    "    if intermed >= 1:\n",
    "        c = colorscale[-1][1]\n",
    "        return c if c[0] != \"#\" else hex_to_rgb(c)\n",
    "\n",
    "    for cutoff, color in colorscale:\n",
    "        if intermed > cutoff:\n",
    "            low_cutoff, low_color = cutoff, color\n",
    "        else:\n",
    "            high_cutoff, high_color = cutoff, color\n",
    "            break\n",
    "\n",
    "    if (low_color[0] == \"#\") or (high_color[0] == \"#\"):\n",
    "        # some color scale names (such as cividis) returns:\n",
    "        # [[loc1, \"hex1\"], [loc2, \"hex2\"], ...]\n",
    "        low_color = hex_to_rgb(low_color)\n",
    "        high_color = hex_to_rgb(high_color)\n",
    "\n",
    "    intermediate_color = plotly.colors.find_intermediate_color(\n",
    "        lowcolor=low_color,\n",
    "        highcolor=high_color,\n",
    "        intermed=((intermed - low_cutoff) / (high_cutoff - low_cutoff)),\n",
    "        colortype=\"rgb\",\n",
    "    )\n",
    "    return intermediate_color\n",
    "\n",
    "def get_plotly_colors(num_points, colorscale):\n",
    "    color_steps = torch.linspace(start=0, end=1, steps=num_points).tolist()\n",
    "    colors = get_color(colorscale, color_steps)\n",
    "    colors = [plotly.colors.unlabel_rgb(color) for color in colors]\n",
    "    colors = torch.tensor(colors, dtype=torch.float, device='cuda').view(1, num_points, 3)\n",
    "    colors = colors.div(255.0).add(-0.5).mul(2)  # Map [0, 255] RGB colors to [-1, 1]\n",
    "    return colors  # (1, P, 3)\n",
    "\n",
    "def get_colormap(flow, H, W):\n",
    "    points = flow.permute(0, 2, 3, 1)\n",
    "    points = points.reshape(points.size(0), points.size(1) * points.size(2), 2)  # (N, K*P, 2)\n",
    "    num_points = points.size(1)\n",
    "    colorscale = ['plasma']\n",
    "    colors = torch.cat([get_plotly_colors(num_points, c) for c in colorscale], 1)  # (1, K*P, 3)\n",
    "    colors = colors.reshape(H, W, 3).cpu().numpy() * 255 \n",
    "\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_input_images(scene_images, target_images):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    num = len(scene_images)\n",
    "    plt.subplot(221), plt.imshow(scene_images[0]), plt.axis('off')\n",
    "    plt.subplot(222), plt.imshow(target_images[0]), plt.axis('off')\n",
    "    plt.subplot(223), plt.imshow(scene_images[num-1]), plt.axis('off')\n",
    "    plt.subplot(224), plt.imshow(target_images[num-1]), plt.axis('off')\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend(out, source, scene, blend_type, mask=None):\n",
    "    if mask is None:\n",
    "        intensity = np.linalg.norm(out, axis=2)\n",
    "        mask = (intensity == 0)[:,:,np.newaxis]   \n",
    "    else:\n",
    "        mask = mask\n",
    "        \n",
    "    if blend_type == 'light':\n",
    "        result = (out * (1 - mask) + source * mask).astype(np.uint8)\n",
    "    else:\n",
    "        result = (out * (1 - mask) + scene * mask).astype(np.uint8) \n",
    "    return result, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_homography(scene_images, target, source=None, blend_type='scale', detector='SIFT', use_colormap=True):\n",
    "    #H, W = 480, 640\n",
    "    #target = cv2.resize(target, (W, H)) \n",
    "    if detector == 'ORB':\n",
    "        detect = cv2.ORB_create()    \n",
    "    elif detector == 'SIFT':\n",
    "        detect = cv2.SIFT_create()\n",
    "    else:\n",
    "        raise ValueError('detector not implemented')\n",
    "    blends = []\n",
    "    masks = []\n",
    "    for scene in scene_images:\n",
    "        #ori_H, ori_W = scene.shape[:2]\n",
    "        #scene = cv2.resize(scene, (W, H))        \n",
    "        kp1, des1 = detect.detectAndCompute(target, None)\n",
    "        kp2, des2 = detect.detectAndCompute(scene, None)           \n",
    "        if des1 is None or des2 is None:\n",
    "            blends.append(None)   \n",
    "            continue\n",
    "        \n",
    "        if detector == 'ORB':\n",
    "            bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)                \n",
    "            matches = bf.match(des1, des2)\n",
    "            \n",
    "        elif detector == 'SIFT':\n",
    "            FLANN_INDEX_KDTREE = 0\n",
    "            indexParams = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "            searchParams = dict(checks=50)\n",
    "            flann = cv2.FlannBasedMatcher(indexParams, searchParams)    \n",
    "            if len(des1)<2 or len(des2)<2:\n",
    "                blends.append(None)\n",
    "                continue\n",
    "            matches = flann.knnMatch(des1, des2, k=2)\n",
    "            matches = [m for m,n in matches if m.distance < 0.7*n.distance]\n",
    "        else:\n",
    "            raise ValueError('detector {} not implemented'.format(detector))\n",
    "        if len(matches) < 4:\n",
    "            blends.append(None)\n",
    "            continue        \n",
    "        matches = sorted(matches, key=lambda x: x.distance)\n",
    "        #print(len(matches))\n",
    "        #img3 = cv2.drawMatches(target, kp1, scene, kp2, matches[:50], target, flags=2)\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in matches[:50]]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches[:50]]).reshape(-1,1,2)        \n",
    "\n",
    "        M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        if M is None:\n",
    "            blends.append(None)\n",
    "            continue\n",
    "        out = cv2.warpPerspective(target, M, (scene.shape[1], scene.shape[0]))        \n",
    "\n",
    "        blend_i, mask_i = blend(out, source, scene, blend_type)\n",
    "        #blend_i = cv2.resize(blend_i, (ori_W, ori_H))\n",
    "        blends.append(blend_i)\n",
    "        masks.append(mask_i)\n",
    "    return blends, masks\n",
    "    plt.figure(figsize=(20,30))\n",
    "    plt.subplot(131), plt.imshow(target[:,:,::-1]), plt.title('target')\n",
    "    plt.subplot(132), plt.imshow(scene[:,:,::-1]), plt.title('scene')\n",
    "    plt.subplot(133), plt.imshow(blend[:,:,::-1]), plt.title('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_pdc(scene_images, target, flow_estimator, estimate_uncertainty, source=None, blend_type='scale', use_colormap=True):            \n",
    "    #H, W = 480, 640\n",
    "    #img1 = cv2.resize(target, (W, H))    \n",
    "    blends = []\n",
    "    masks = []\n",
    "    for scene in scene_images:        \n",
    "        #H_ori, W_ori = scene.shape[:2]                \n",
    "        #img2 = cv2.resize(scene, (W, H))\n",
    "        target = cv2.resize(target, (scene.shape[1], scene.shape[0]))\n",
    "        Is_original = np.ascontiguousarray(target)\n",
    "        It_original = np.ascontiguousarray(scene)\n",
    "        Is_tensor = torch.from_numpy(Is_original).permute(2,0,1).unsqueeze(0)\n",
    "        It_tensor = torch.from_numpy(It_original).permute(2,0,1).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            flow_est, uncertainty_est = flow_estimator.estimate_flow_and_confidence_map(Is_tensor, It_tensor)\n",
    "\n",
    "        flow = flow_est[0].permute([1,2,0]).cpu().detach().numpy()\n",
    "        out = remap_using_flow_fields(Is_original, flow[:,:,0], flow[:,:,1])\n",
    "        #img_warp = cv2.resize(img_warp, (W_ori, H_ori))\n",
    "        \n",
    "        blend_i, mask_i = blend(out, source, scene, blend_type) \n",
    "        #blend_i = cv2.resize(blend_i, (W_ori, H_ori))\n",
    "        blends.append(blend_i)\n",
    "        masks.append(mask_i)\n",
    "    return blends, masks\n",
    "        \n",
    "\n",
    "    '''\n",
    "        confidence_map = uncertainty_est['p_r'].squeeze().detach().cpu().numpy()\n",
    "\n",
    "        plt.figure(figsize=(20,30))\n",
    "        plt.subplot(141), plt.imshow(img1_ori[:,:,::-1]), plt.axis('off')\n",
    "        plt.subplot(142), plt.imshow(img2_ori[:,:,::-1]), plt.axis('off')\n",
    "        plt.subplot(143), plt.imshow(blend[:,:,::-1]), plt.axis('off')\n",
    "        #plt.subplot(144), plt.imshow(confidence_map)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(image_true, image_test, mask, heatmap=False, with_mask=True):\n",
    "    check_shape_equality(image_true, image_test)    \n",
    "\n",
    "    if image_true.dtype != image_test.dtype:\n",
    "        warn(\"Inputs have mismatched dtype. Setting data_range based on \"\n",
    "                \"im_true.\", stacklevel=2)\n",
    "    dmin, dmax = dtype_range[image_true.dtype.type]\n",
    "    true_min, true_max = np.min(image_true), np.max(image_true)\n",
    "    if true_max > dmax or true_min < dmin:\n",
    "        raise ValueError(\n",
    "            \"im_true has intensity values outside the range expected for \"\n",
    "            \"its data type. Please manually specify the data_range\")\n",
    "    if true_min >= 0:\n",
    "        # most common case (255 for uint8, 1 for float)\n",
    "        data_range = dmax\n",
    "    else:\n",
    "        data_range = dmax - dmin\n",
    "    \n",
    "    image_true = image_true.astype(np.float64)\n",
    "    image_test = image_test.astype(np.float64)\n",
    "    if not with_mask:                      \n",
    "        error_mask = ((image_true - image_test) ** 2).astype(np.float64)\n",
    "        err = np.mean(error_mask, dtype=np.float64)\n",
    "    else:\n",
    "        cnt = np.count_nonzero(1-mask) * image_true.shape[2]\n",
    "        error_mask = ((image_true*(1-mask) - image_test*(1-mask))**2).astype(np.float64)\n",
    "        sum = np.sum(error_mask)    \n",
    "        err = sum/cnt\n",
    "        \n",
    "        # plt.figure(facecolor='white')\n",
    "        # plt.subplot(121), plt.imshow(image_true.astype(np.uint8)*(1-mask))\n",
    "        # plt.subplot(122), plt.imshow(image_test.astype(np.uint8)*(1-mask))\n",
    "        \n",
    "    score = 10 * np.log10((data_range ** 2) / err)\n",
    "    if heatmap:             \n",
    "        # error_heatmap = np.zeros_like(error_mask)\n",
    "        error_mask = np.mean(error_mask, axis=2)   \n",
    "        # np.save('./error_mask.npy', error_mask)\n",
    "\n",
    "        x,y = np.nonzero(error_mask)\n",
    "        error_mask[x,y] = 10 * np.log10((data_range ** 2) / error_mask[x,y])        \n",
    "        error_mask = error_mask / 30\n",
    "        # colorscale=['plasma']\n",
    "        # colors = torch.cat([get_plotly_colors(600, c) for c in colorscale], 1)[0].cpu().numpy()\n",
    "        # #(600, 3) (640, 480, 3) (640, 480)\n",
    "        \n",
    "        # for y in range(error_mask.shape[0]):\n",
    "        #     for x in range(error_mask.shape[1]):\n",
    "        #         print(error_mask[y,x])\n",
    "        #         error_heatmap[y,x,:] = colors[error_mask[y,x].astype(np.uint8)+350,:]\n",
    "        # error_heatmap = (error_heatmap * 255).astype(np.uint8)*(1-mask)\n",
    "        \n",
    "        error_mask = (error_mask * 255).astype(np.uint8)\n",
    "        error_heatmap = cv2.applyColorMap(error_mask, cv2.COLORMAP_JET)*(1-mask)\n",
    "        return score, error_heatmap\n",
    "    else:\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import uniform_filter\n",
    "def SSIM(im1, im2, mask, multichannel=True, heatmap=False, with_mask=True):\n",
    "    check_shape_equality(im1, im2)\n",
    "\n",
    "    if multichannel:\n",
    "        # loop over channels\n",
    "        nch = im1.shape[-1]\n",
    "        mssim = np.empty(nch)\n",
    "        S = np.empty(im1.shape)\n",
    "        for ch in range(nch):\n",
    "            ch_result = SSIM(im1[..., ch], im2[..., ch], multichannel=False, mask=mask, heatmap=heatmap)\n",
    "            mssim[..., ch], S[...,ch] = ch_result\n",
    "        mssim = mssim.mean()\n",
    "        if heatmap:\n",
    "            S = np.mean(S, axis=2)                        \n",
    "            S = (S+1)/2\n",
    "            S = (S * 255).astype(np.uint8)            \n",
    "            error_heatmap = cv2.applyColorMap(S, cv2.COLORMAP_JET)*(1-mask)\n",
    "            return mssim, error_heatmap\n",
    "        else:\n",
    "            return mssim\n",
    "\n",
    "    if im1.dtype != im2.dtype:\n",
    "        warn(\"Inputs have mismatched dtype.  Setting data_range based on im1.dtype.\", stacklevel=2)\n",
    "    dmin, dmax = dtype_range[im1.dtype.type]\n",
    "    data_range = dmax - dmin\n",
    "    \n",
    "    K1 = 0.01\n",
    "    K2 = 0.03\n",
    "    R = data_range\n",
    "    C1 = (K1 * R) ** 2\n",
    "    C2 = (K2 * R) ** 2  \n",
    "    S = np.ones_like(im1)\n",
    "    win_size=3\n",
    "\n",
    "    # ndimage filters need floating point data\n",
    "    if not with_mask:\n",
    "        im1 = im1.astype(np.float64)\n",
    "        im2 = im2.astype(np.float64)\n",
    "    else:\n",
    "        mask = mask.squeeze()\n",
    "        im1 = (im1*(1-mask)).astype(np.float64)\n",
    "        im2 = (im2*(1-mask)).astype(np.float64)\n",
    "    \n",
    "    if heatmap:\n",
    "        ux = uniform_filter(im1, size=win_size)\n",
    "        uy = uniform_filter(im2, size=win_size)\n",
    "\n",
    "        uxx = uniform_filter(im1*im1, size=win_size)\n",
    "        uyy = uniform_filter(im2*im2, size=win_size)\n",
    "        uxy = uniform_filter(im1*im2, size=win_size)\n",
    "        vx = uxx - ux*ux \n",
    "        vy = uyy - uy*uy\n",
    "        vxy = uxy - ux*uy\n",
    "\n",
    "        A1, A2, B1, B2 = ((2 * ux * uy + C1,\n",
    "                           2 * vxy + C2,\n",
    "                           ux ** 2 + uy ** 2 + C1,\n",
    "                           vx + vy + C2))\n",
    "        D = B1 * B2\n",
    "        S = (A1 * A2) / D    \n",
    "    \n",
    "\n",
    "    if not with_mask:\n",
    "        mask = np.zeros_like(im1)\n",
    "        x,y = np.nonzero(1-mask)\n",
    "    else:\n",
    "        #x,y,_ = np.nonzero(1-mask)\n",
    "        x,y = np.nonzero(1-mask)\n",
    "    im1_pixel = im1[x,y]\n",
    "    im2_pixel = im2[x,y]\n",
    "\n",
    "    ux = np.mean(im1_pixel)\n",
    "    uy = np.mean(im2_pixel)\n",
    "    uxy = np.mean(im1_pixel*im2_pixel)\n",
    "    vx = np.var(im1_pixel)\n",
    "    vy = np.var(im2_pixel)\n",
    "    vxy = uxy - ux*uy\n",
    "\n",
    "    ssim = (2*ux*uy+C1)*(2*vxy+C2)/((ux**2+uy**2+C1)*(vx+vy+C2))\n",
    "    return ssim, S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(id, output_images, masks, save_root, scene_images=None, source=None, blend_type='scale', with_mask=False, save=True, heatmap=False):   \n",
    "    if blend_type != 'light' and len(output_images)!=len(scene_images):\n",
    "        raise ValueError('output images should have the same number as scene images')\n",
    "    if save:\n",
    "        save_file = os.path.join(save_root, 'output.txt')\n",
    "    result = {'p':[], 's':[], 'ce':[], 'fail':0, 'psnr_heatmap':[], 'ssim_heatmap':[]}    \n",
    "    if save:\n",
    "        with open(save_file, 'a') as f:\n",
    "            f.write('id: {}\\n'.format(str(id).zfill(4)))\n",
    "\n",
    "    for i, output in enumerate(output_images):\n",
    "        if output is None: \n",
    "            result['p'].append(0)\n",
    "            result['s'].append(-1)\n",
    "            result['ce'].append(-1)\n",
    "            result['fail'] = result['fail']+1            \n",
    "            if save:\n",
    "                with open(save_file, 'a') as f:\n",
    "                    f.write('no.{:2d}\\t Failed\\n'.format(i))\n",
    "            continue\n",
    "\n",
    "        if blend_type == 'light':\n",
    "            scene = source\n",
    "        else:\n",
    "            scene = scene_images[i]\n",
    "        \n",
    "        mask = masks[i]                    \n",
    "        if heatmap:\n",
    "            p, psnr_heatmap = PSNR(output, scene, mask=mask, heatmap=heatmap, with_mask=with_mask)\n",
    "            s, ssim_heatmap = SSIM(output, scene, multichannel=True, mask=mask, heatmap=heatmap, with_mask=with_mask)\n",
    "            result['psnr_heatmap'].append(psnr_heatmap)\n",
    "            result['ssim_heatmap'].append(ssim_heatmap)\n",
    "        else:\n",
    "            p = PSNR(output, scene, mask=mask, heatmap=heatmap, with_mask=with_mask)\n",
    "            s = SSIM(output, scene, multichannel=True, mask=mask, heatmap=heatmap, with_mask=with_mask)                                \n",
    "        # plt.figure(facecolor='white')\n",
    "        # plt.subplot(121), plt.imshow(output*(1-mask)), plt.title('output'), plt.axis('off')\n",
    "        # plt.subplot(122), plt.imshow(scene*(1-mask)), plt.title('scene'), plt.axis('off')\n",
    "            \n",
    "        result['p'].append(round(p, 2))\n",
    "        result['s'].append(round(s, 2))          \n",
    "            \n",
    "        # print('no.{:2d}\\t PSNR:{:.2f}\\t SSIM:{:.2f}\\t census error:{:.2f}'.format(i, p, s, ce))\n",
    "        # print('no.{:2d}\\t PSNR:{:.2f}\\t SSIM:{:.2f}\\t'.format(i, p, s))\n",
    "        if save:\n",
    "            with open(save_file, 'a') as f:\n",
    "                f.write('no.{:2d}\\t PSNR:{:.2f}\\t SSIM:{:.2f}\\t\\n'.format(i, p, s))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coords_grid(batch, ht, wd):\n",
    "    coords = torch.meshgrid(torch.arange(ht), torch.arange(wd))    \n",
    "    coords = torch.stack(coords[::-1], dim=0).float()     \n",
    "\n",
    "    return coords[None].repeat(batch, 1, 1, 1)\n",
    "    #return np.asarray(coords)\n",
    "    \n",
    "def image_flow_warp(image, flow, padding_mode='zeros'):\n",
    "    '''\n",
    "    Input:\n",
    "        image: HxWx3 numpy\n",
    "        flow: HxWx2 torch.Tensor\n",
    "    Output:\n",
    "        outImg: HxWx3 numpy\n",
    "    '''\n",
    "    image = torch.from_numpy(image)\n",
    "    if image.ndim == 2:\n",
    "        image = image[None].permute([1,2,0])\n",
    "    H, W, _ = image.shape\n",
    "    coords = coords_grid(1, H, W).cuda().float().contiguous()\n",
    "    flow = flow[None].repeat(1, 1, 1, 1).permute([0, 3, 1, 2]).float().contiguous()    \n",
    "    grid = (flow + coords).permute([0, 2, 3, 1]).contiguous()   # (1, H, W, 2)  \n",
    "    \n",
    "    grid[:, :, :, 0] = (grid[:, :, :, 0] * 2 - W + 1) / (W - 1)\n",
    "    grid[:, :, :, 1] = (grid[:, :, :, 1] * 2 - H + 1) / (H - 1)    \n",
    "    image = image[None].permute([0, 3, 1, 2]).cuda().float()\n",
    "    \n",
    "    outImg = F.grid_sample(image, grid, padding_mode=padding_mode, align_corners=False)[0].cpu().numpy().transpose([1, 2, 0])\n",
    "    return outImg\n",
    "    \n",
    "def image_forward_warp(image, flow, padding_mode='zeros'):\n",
    "    '''\n",
    "    Input:\n",
    "        image: HxWx3 numpy\n",
    "        flow: HxWx2 torch.Tensor\n",
    "    Output:\n",
    "        outImg: HxWx3 numpy\n",
    "    '''\n",
    "    forward_warp = ForwardWarp()    \n",
    "    image = torch.from_numpy(image).permute([2,0,1])[None].cuda()\n",
    "    # flow = torch.from_numpy(flow).permute([2,0,1])[None].cuda()\n",
    "    flow = flow.permute([2,0,1])[None].cuda()\n",
    "    out = forward_warp(image, flow)\n",
    "    image = (out[0][0] / out[1][0] + 1e-6).cpu().permute([1,2,0]).numpy().astype(np.uint8)\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_life(scene_images, target, estimator, source=None, blend_type='scale', warp='grid_sample', use_colormap=True):    \n",
    "    #H, W = 480, 640    \n",
    "    blends = []\n",
    "    masks = []\n",
    "    blends_colormap = []\n",
    "    for scene in scene_images:        \n",
    "        #ori_H, ori_W = scene.shape[:2]\n",
    "        #scene = cv2.resize(scene, (W, H))\n",
    "        target = cv2.resize(target, (scene.shape[1], scene.shape[0]))\n",
    "        if './Twins-new' in sys.path:\n",
    "            flow = estimator.estimate(target, scene)           \n",
    "        else:\n",
    "            flow = estimator.estimate(scene, target)           \n",
    "        \n",
    "        if use_colormap:\n",
    "            colormap = get_colormap(flow, scene.shape[0], scene.shape[1])\n",
    "            #cv2.imwrite('./colormap.jpg', cv2.resize((colormap[:,:,::-1]+256)/2, (640,480)))\n",
    "\n",
    "        mask = None\n",
    "        if warp == 'grid_sample':\n",
    "            if './Twins-new' in sys.path:\n",
    "                out = image_forward_warp(target, flow[0].permute([1,2,0])) \n",
    "                mask_origin = (np.ones(shape=(target.shape[0], target.shape[1], 1)) * 255).astype(np.uint8)\n",
    "                mask_origin = image_forward_warp(mask_origin, flow[0].permute([1,2,0]),padding_mode='zeros')\n",
    "                mask = (255 - mask_origin).astype(np.float64) / 255.0 \n",
    "                # mask_origin = np.ones(shape=(target.shape[0], target.shape[1], 1)).astype(np.float64) \n",
    "                # mask_origin = image_forward_warp(mask_origin, flow[0].permute([1,2,0]),padding_mode='zeros')\n",
    "                # mask = (1 - mask_origin)\n",
    "                if use_colormap:\n",
    "                    out_colormap =  image_forward_warp(colormap, flow[0].permute([1,2,0])) \n",
    "                    out_colormap = ((out_colormap + 256) / 2)\n",
    "                    mask_colormap = np.ones_like(colormap).astype(np.float32) / 2\n",
    "                    mask_colormap = image_forward_warp(mask_colormap, flow[0].permute([1,2,0]))\n",
    "                    mask_colormap = (1 - mask_colormap)                    \n",
    "            else:\n",
    "                out = image_flow_warp(target, flow[0].permute([1,2,0]))  \n",
    "                mask_origin = np.ones(shape=(target.shape[0], target.shape[1], 1)).astype(np.float64) \n",
    "                mask_origin = image_flow_warp(mask_origin, flow[0].permute([1,2,0]),padding_mode='zeros')\n",
    "                mask = (1 - mask_origin)\n",
    "                if use_colormap:\n",
    "                    out_colormap =  image_flow_warp(colormap, flow[0].permute([1,2,0])) \n",
    "                    out_colormap = ((out_colormap + 256) / 2)\n",
    "                    # cv2.imwrite('./out_colormap.jpg', out_colormap)   \n",
    "                    mask_colormap = np.ones_like(colormap).astype(np.float32) / 2\n",
    "                    mask_colormap = image_flow_warp(mask_colormap, flow[0].permute([1,2,0]))\n",
    "                    mask_colormap = (1 - mask_colormap) \n",
    "\n",
    "            # plt.figure()\n",
    "            # plt.subplot(141), plt.imshow(out), plt.title('out')\n",
    "            # plt.subplot(142), plt.imshow(mask), plt.title('mask')\n",
    "            # plt.subplot(143), plt.imshow(scene), plt.title('scene')\n",
    "            # plt.subplot(144), plt.imshow((scene*(1-mask)).astype(np.uint8)), plt.title('scene with mask')\n",
    "                      \n",
    "        elif warp == 'homography':\n",
    "        # RANSAC homography\n",
    "            flow = flow[0].permute([1,2,0])\n",
    "            image = target\n",
    "            img = image\n",
    "            sce = scene\n",
    "            image = torch.from_numpy(image)\n",
    "            if image.ndim == 2:\n",
    "                image = image[None].permute([1,2,0])\n",
    "            H, W, _ = image.shape\n",
    "            coords = coords_grid(1, H, W).cuda().float().contiguous()\n",
    "            flow = flow[None].repeat(1, 1, 1, 1).permute([0, 3, 1, 2]).float().contiguous()    \n",
    "            grid = (flow + coords).permute([0, 2, 3, 1]).contiguous()   # (1, H, W, 2)\n",
    "            grid = grid[0].cpu()\n",
    "            src_pts = []\n",
    "            dst_pts = []\n",
    "            for y in range(H):\n",
    "                for x in range(W):\n",
    "                    if grid[y,x,0]>=0 and grid[y,x,0]<W and grid[y,x,1]>=0 and grid[y,x,1]<H:\n",
    "                        src_pts.append((grid[y,x,0], grid[y,x,1]))\n",
    "                        dst_pts.append((x, y))                        \n",
    "            src_pts = np.float32(src_pts)\n",
    "            dst_pts = np.float32(dst_pts)\n",
    "            '''\n",
    "            num = len(src_pts)\n",
    "            for idx in range(num):\n",
    "                print(src_pts[idx], dst_pts[idx])\n",
    "                cv2.circle(img, (int(src_pts[idx][0]), int(src_pts[idx][1])), 1, (255, 0, 0))\n",
    "                cv2.circle(sce, (int(dst_pts[idx][0]), int(dst_pts[idx][1])), 1, (255, 0, 0))\n",
    "            plt.figure(facecolor='white')\n",
    "            plt.subplot(1,2,1), plt.imshow(img)\n",
    "            plt.subplot(1,2,2), plt.imshow(sce)\n",
    "            plt.show()\n",
    "            '''\n",
    "            M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "            if M is None:\n",
    "                blends.append(None)\n",
    "                continue\n",
    "            out = cv2.warpPerspective(target, M, (scene.shape[1], scene.shape[0]))        \n",
    "\n",
    "        blend_i, mask_i = blend(out, source, scene, blend_type, mask=mask)        \n",
    "        blends.append(blend_i)\n",
    "        masks.append(mask_i)\n",
    "        if use_colormap:            \n",
    "            blend_colormap = (out_colormap * (1 - mask_colormap) + scene * mask_colormap).astype(np.uint8) \n",
    "            blends_colormap.append(blend_colormap)\n",
    "    return blends, masks, blends_colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_SPSG(scene_images, target, matching=None, source=None, blend_type='scale', save_root=None, use_colormap=True):\n",
    "    blends = []\n",
    "    masks = []\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    for idx, scene in enumerate(scene_images):\n",
    "        target = cv2.resize(target, (scene.shape[1], scene.shape[0]))\n",
    "        target_gray = cv2.cvtColor(target, cv2.COLOR_BGR2GRAY)\n",
    "        scene_gray = cv2.cvtColor(scene, cv2.COLOR_BGR2GRAY)\n",
    "        inp0 = frame2tensor(target_gray, device=device)\n",
    "        inp1 = frame2tensor(scene_gray, device=device)        \n",
    "        pred = matching({'image0': inp0, 'image1': inp1})\n",
    "        pred = {k: v[0].cpu().numpy() for k, v in pred.items()}\n",
    "        kpts0, kpts1 = pred['keypoints0'], pred['keypoints1']\n",
    "        matches, conf = pred['matches0'], pred['matching_scores0']\n",
    "\n",
    "        valid = matches > -1          \n",
    "        mkpts0 = kpts0[valid]\n",
    "        mkpts1 = kpts1[matches[valid]] \n",
    "        mconf = conf[valid]\n",
    "        \n",
    "        # plot_image_pair([target, scene])        \n",
    "        # plot_keypoints(kpts0, kpts1, color='k', ps=4)\n",
    "        # plot_keypoints(kpts0, kpts1, color='w', ps=2)\n",
    "        # plot_matches(mkpts0, mkpts1, color='r')\n",
    "        # plt.show()\n",
    "        # plt.savefig(os.path.join(save_root, 'SPSG_match_'+str(idx)+'.jpg'), bbox_inches='tight', pad_inches=0)\n",
    "        \n",
    "        valid = mconf > 0.5\n",
    "        mkpts0 = mkpts0[valid]\n",
    "        mkpts1 = mkpts1[valid]\n",
    "        \n",
    "        if np.count_nonzero(valid) < 4:\n",
    "            blends.append(None)\n",
    "            masks.append(None)\n",
    "            continue\n",
    "        \n",
    "        src_pts = np.float32(mkpts0).reshape(-1,1,2)\n",
    "        dst_pts = np.float32(mkpts1).reshape(-1,1,2)\n",
    "        M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        if M is None:\n",
    "            blends.append(None)\n",
    "            masks.append(None)\n",
    "            continue\n",
    "        out = cv2.warpPerspective(target, M, (scene.shape[1], scene.shape[0]))        \n",
    "\n",
    "        blend_i, mask_i = blend(out, source, scene, blend_type)\n",
    "        #blend_i = cv2.resize(blend_i, (ori_W, ori_H))\n",
    "        blends.append(blend_i)\n",
    "        masks.append(mask_i)\n",
    "        \n",
    "        \n",
    "    return blends, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(id, \n",
    "         scene_images, \n",
    "         target,           \n",
    "         save_root, \n",
    "         blend_method='life',\n",
    "         blend_type='scale', \n",
    "         estimator=None, \n",
    "         flow_estimator=None, \n",
    "         estimate_uncertainty=None, \n",
    "         matching=None,         \n",
    "         source=None,\n",
    "         detector='SIFT',\n",
    "         with_mask = False,\n",
    "         use_colormap=True,\n",
    "         draw = True,\n",
    "         save = True,\n",
    "         warp = 'grid_sample',\n",
    "         heatmap=False):   \n",
    "    '''\n",
    "    Args:\n",
    "        @id: (int) target image id, for logging\n",
    "        @scene_images: (list) test scene images\n",
    "        @target: (array) target image\n",
    "        @save_root: (string) \n",
    "        @blend_method: (string, 'life') ['life', 'homography', 'pdc']\n",
    "        @blend_type: (string, 'scale') ['scale', 'light', 'viewpoint']\n",
    "        @estimator: model to estimate when blend_method=='life'\n",
    "        @flow_estimator: model to estimate when blend_method=='pdc'\n",
    "        @estimate_uncertainty: check result uncertainty when blend_method=='pdc'\n",
    "        @matching: SPSG\n",
    "        @coarseModel & network: RANSAC-Flow\n",
    "        @source: source image to calculate metrics when blend_type=='lighting'\n",
    "        @detector: (string, 'SIFT) ['SIFT', 'ORB'] detector used in homography\n",
    "        @with_mask: (bool) calculate metrics with or without mask\n",
    "        @draw: (bool) show results or not\n",
    "        @save: (bool) save results or not\n",
    "        @warp: (string,'grid_sample') ['grid_sample', 'homography'] warp method for LIFE model\n",
    "    '''\n",
    "    if blend_method in ['life', 'raft', 'biraft', 'ms', 'twins', 'occ', 'twins-twostage', 'twins-onestage']:\n",
    "        if estimator is None:\n",
    "            raise ValueError('estimator not set')        \n",
    "        out, mask, out_colormap = blend_life(scene_images, target, estimator=estimator, source=source, blend_type=blend_type, warp=warp, use_colormap=use_colormap)\n",
    "    elif blend_method == 'homography':        \n",
    "        out, mask = blend_homography(scene_images, target, source=source, blend_type=blend_type, detector=detector, use_colormap=use_colormap)\n",
    "    elif blend_method == 'pdc':\n",
    "        if flow_estimator is None:\n",
    "            raise ValueError('estimator not set')\n",
    "        out, mask = blend_pdc(scene_images, target, flow_estimator=flow_estimator, estimate_uncertainty=estimate_uncertainty, source=source, blend_type=blend_type, use_colormap=use_colormap)\n",
    "    elif blend_method == 'SPSG':\n",
    "        save_root = os.path.join(save_root, str(id).zfill(4))\n",
    "        if save and not os.path.exists(save_root):\n",
    "            os.makedirs(save_root)\n",
    "        out, mask = blend_SPSG(scene_images, target, matching=matching, source=source, blend_type=blend_type, save_root=save_root, use_colormap=use_colormap)\n",
    "    else:\n",
    "        raise ValueError('blend method has not been implemented')\n",
    "\n",
    "        \n",
    "    if blend_type == 'light':\n",
    "        result = metrics(id, out, mask, save_root=save_root, source=source, blend_type=blend_type, with_mask=with_mask, heatmap=heatmap, save=save)\n",
    "    else:\n",
    "        result = metrics(id, out, mask, save_root=save_root, scene_images =scene_images, blend_type=blend_type, with_mask=with_mask, heatmap=heatmap, save=save)\n",
    "        \n",
    "    if draw or save: \n",
    "        # save_root = os.path.join(save_root, str(id).zfill(4))\n",
    "        # if save and not os.path.exists(save_root):\n",
    "        #     os.makedirs(save_root)\n",
    "        for i in range(len(scene_images)): \n",
    "            if out[i] is None:\n",
    "                continue\n",
    "            title = 'PSNR: '+str(result['p'][i])+' SSIM: '+str(result['s'][i])\n",
    "            # plt.figure(figsize=(10,15), facecolor='white')      \n",
    "                        \n",
    "            # plt.subplot(2, 2, 1)\n",
    "            # plt.imshow(target), plt.axis('off')# , plt.title('target '+str(id).zfill(4))        \n",
    "            \n",
    "            if not with_mask:\n",
    "                if blend_type == 'viewpoint':\n",
    "                    scene_images[i] = resize_viewpoint(scene_images[i])\n",
    "                    out[i] = resize_viewpoint(out[i])\n",
    "                    if use_colormap:\n",
    "                        out_colormap[i] = resize_viewpoint(out_colormap[i])                    \n",
    "                elif blend_type == 'light':\n",
    "                    scene_images[i] = resize_lighting(scene_images[i])\n",
    "                    out[i] = resize_lighting(out[i])\n",
    "                    if use_colormap:\n",
    "                        out_colormap[i] = resize_lighting(out_colormap[i])\n",
    "            if draw: \n",
    "                plt.figure(facecolor='white')\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.imshow(scene_images[i]), plt.axis('off')# , plt.title('scene '+str(i).zfill(4))        \n",
    "                plt.subplot(1, 2, 2) \n",
    "                plt.imshow(out[i]), plt.axis('off')#, plt.title(title)\n",
    "                # plt.subplot(1, 2, 2) \n",
    "                # if with_mask:\n",
    "                #     plt.imshow(out[i]*(1-mask[i])), plt.axis('off') #, plt.title(title)  \n",
    "                # else:                    \n",
    "                #     plt.imshow(out[i]), plt.axis('off')                \n",
    "              \n",
    "            if save: \n",
    "                # plt.savefig(os.path.join(save_root,str(i)+'_'+title+'.png'), dpi=200, bbox_inches='tight')            \n",
    "                io.imsave(os.path.join(save_root, str(i)+'_out.png'), out[i].astype(np.uint8))                \n",
    "                io.imsave(os.path.join(save_root, str(i)+'_scene.png'), scene_images[i].astype(np.uint8))\n",
    "                if use_colormap:\n",
    "                    io.imsave(os.path.join(save_root, str(i)+'_out_colormap.png'), out_colormap[i])\n",
    "                if heatmap:\n",
    "                    io.imsave(os.path.join(save_root, str(i)+'_psnr_heatmap.png'), resize_lighting(result['psnr_heatmap'][i]))\n",
    "                    io.imsave(os.path.join(save_root, str(i)+'_ssim_heatmap.png'), resize_lighting(result['ssim_heatmap'][i]))\n",
    "            plt.show()\n",
    "            \n",
    "    return (out, result)\n",
    "\n",
    "def resize_viewpoint(img):\n",
    "    if img.shape[0] > img.shape[1]:\n",
    "        resize = cv2.flip(cv2.transpose(img), 0)\n",
    "        return resize\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "def resize_lighting(img):\n",
    "    if img.shape[0] > img.shape[1]:        \n",
    "        region = img[140:500, 0:480]\n",
    "        resize = cv2.resize(region, (640, 480))\n",
    "        return resize \n",
    "    else:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(root = './assets/',\n",
    "        blend_type = 'scale',\n",
    "        blend_method = 'life', \n",
    "        img_num = 5, \n",
    "        start_img_id = 0,\n",
    "        start_scene_id = 0,\n",
    "        scn_num = 10,\n",
    "        source_id = -1,\n",
    "        H = 480,\n",
    "        W = 640,\n",
    "        with_mask = False,\n",
    "        use_colormap = True,\n",
    "        draw = True,\n",
    "        save = True,\n",
    "        save_root=\"\",\n",
    "        detector=\"SIFT\",\n",
    "        multisample=True,\n",
    "        folder=\"\",\n",
    "        warp='grid_sample',\n",
    "        heatmap=False):\n",
    "    '''\n",
    "    Args:\n",
    "        @root: (string, './assets/') image data root\n",
    "        @blend_type: (string, 'scale) ['scale', 'light', 'viewpoint', 'deformation', 'occlusion']\n",
    "        @blend_method: (string, 'life') ['homography', 'pdc', 'life', 'raft', 'biraft', 'ms', 'occ', 'twins', 'twins-twostage', 'twins-onestage']\n",
    "        @img_num: (int, 5) number of test images\n",
    "        @start_img_id: (int, 0) test from image with id=start_img_id\n",
    "        @start_scene_id: (int, 0) test from scene image with id=start_scene_id\n",
    "        @scn_num: (int, 10) number of scene images per test image\n",
    "        @source_id: if blend_type=='light', source id should be specified for metrics calculation\n",
    "        @(W, H): resize images\n",
    "        @with_mask: caculate PSNR/SSIM with or without mask\n",
    "        @draw: (bool)\n",
    "        @save: (bool)\n",
    "        @detector: (string, 'SIFT') ['SIFT', 'ORB']\n",
    "        @multisample: (bool, True) if False(not one of blend_type), specify scene images folder\n",
    "        @warp: (string, 'grid_sample') ['grid_sample', 'homography'] warp method for LIFE model\n",
    "    Ouput:\n",
    "        folder '{blend_method}_output_{time}' with output images and output.txt(metrics) will be created under folder {blend_type}\n",
    "    '''\n",
    "    # path setting\n",
    "    if blend_type == 'light':\n",
    "        if source_id == -1:\n",
    "            raise FileExistsError('no source image id specified.')    \n",
    "    if multisample:\n",
    "        scene_root = os.path.join(root, blend_type)\n",
    "    else:\n",
    "        if folder==\"\":\n",
    "            raise FileNotFoundError(\"input folder name\")\n",
    "        scene_root = os.path.join(root, folder) \n",
    "    # time = datetime.datetime.now()\n",
    "    # suffix = datetime.datetime.strftime(time, '%m%d%H%M')\n",
    "    # if not with_mask:\n",
    "    #     save_root = os.path.join(scene_root, blend_method+'_output_'+suffix)\n",
    "    # else:\n",
    "    #     save_root = os.path.join(scene_root, blend_method+'_output_mask_'+suffix)\n",
    "    if save and not os.path.exists(save_root):\n",
    "        os.makedirs(save_root)\n",
    "        print('save image to '+save_root)\n",
    "\n",
    "    # data loading\n",
    "    if H > W:\n",
    "        H, W = W, H #keep H < W\n",
    "    scene_images = []\n",
    "    target_images = []    \n",
    "    for id in range(img_num):\n",
    "        id = id + start_img_id\n",
    "        scene_image = []\n",
    "        for i in range(start_scene_id, scn_num):            \n",
    "            scene_path = os.path.join(scene_root, str(id).zfill(4) + \"_\" + blend_type + \"_\"+str(i)+\".jpg\")            \n",
    "            scene = io.imread(scene_path)\n",
    "            if scene.shape[0] > scene.shape[1]: # H > W\n",
    "                scene = cv2.resize(scene, (H, W))\n",
    "            else: # H < W\n",
    "                scene = cv2.resize(scene, (W, H))\n",
    "            scene_image.append(scene)\n",
    "        scene_images.append(scene_image)\n",
    "\n",
    "\n",
    "        target_path = os.path.join(root, str(id).zfill(4) + \".jpg\")\n",
    "        target_image = io.imread(target_path)\n",
    "        if target_image.shape[0] > target_image.shape[1]: # H > W\n",
    "            target_image = cv2.resize(target_image, (H, W))\n",
    "        else:\n",
    "            target_image = cv2.resize(target_image, (W, H))        \n",
    "        target_images.append(target_image)\n",
    "\n",
    "    total = len(scene_images)*len(scene_images[0])\n",
    "    print('input {}x{} scene images'.format(len(scene_images), len(scene_images[0])))    \n",
    "    print('input {} target images'.format(len(target_images)))\n",
    "        \n",
    "    # show_input_images(scene_images, target_images)\n",
    "\n",
    "    # model loading\n",
    "    print('blend method: ', blend_method)    \n",
    "        \n",
    "    if blend_method == 'pdc':\n",
    "        args = easydic({\n",
    "            'model': 'PDCNet',\n",
    "            'pre_trained_model_type': 'megadepth',\n",
    "            'path_to_pre_trained_models': '/home/weihong/work/Optical_Flow/DenseMatching/pre_trained_models',\n",
    "            'local_optim_iter': 7,\n",
    "            'optim_iter': 3,\n",
    "            'network_type': None\n",
    "        })\n",
    "        flow_estimator, estimate_uncertainty = select_model(\n",
    "            args.model, \n",
    "            args.pre_trained_model_type, \n",
    "            args,\n",
    "            args.optim_iter, \n",
    "            args.local_optim_iter,\n",
    "            path_to_pre_trained_models=args.path_to_pre_trained_models)\n",
    "\n",
    "    elif blend_method == 'SPSG':\n",
    "        opt = easydic({\n",
    "            'nms_radius': 4,\n",
    "            'keypoint_threshold': 0.005,\n",
    "            'max_keypoints': 1024,\n",
    "            'superglue': 'indoor',\n",
    "            'sinkhorn_iterations': 20,\n",
    "            'match_threshold': 0.2,\n",
    "        })\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print('Running inference on device \\\"{}\\\"'.format(device))\n",
    "        config = {\n",
    "            'superpoint': {\n",
    "                'nms_radius': opt.nms_radius,\n",
    "                'keypoint_threshold': opt.keypoint_threshold,\n",
    "                'max_keypoints': opt.max_keypoints\n",
    "            },\n",
    "            'superglue': {\n",
    "                'weights': opt.superglue,\n",
    "                'sinkhorn_iterations': opt.sinkhorn_iterations,\n",
    "                'match_threshold': opt.match_threshold,\n",
    "            }\n",
    "        }\n",
    "        matching = Matching(config).eval().to(device)\n",
    "    elif blend_method == 'homography':\n",
    "        print('detector: '+ detector)\n",
    "    else:\n",
    "        if blend_method == 'life':\n",
    "            args = get_life_args()  \n",
    "        elif 'twins' in blend_method:\n",
    "            args = get_twins_args()\n",
    "            args.fnet = 'twins'\n",
    "            if 'twostage' in blend_method:\n",
    "                args.model = './model/twostage.pth'\n",
    "                args.twoscale = True\n",
    "            elif 'onestage' in blend_method:\n",
    "                args.model = './model/twins-onestage.pth'\n",
    "                args.twoscale = False\n",
    "                args.dim_corr_all = 192\n",
    "        else:\n",
    "            args = get_raft_args()\n",
    "            if blend_method == 'biraft':\n",
    "                args.model = './model/biRAFT_latest.pth'\n",
    "            elif blend_method == 'ms':\n",
    "                args.model = './model/MultiScale_latest.pth'\n",
    "            elif blend_method=='occ':\n",
    "                args.model = \"./model/RAFT_twins_bs12_ep20.pth\"  \n",
    "                args.fnet = 'twins'              \n",
    "        #for k, v in vars(args).items():\n",
    "        #    print(k,'=',v)\n",
    "        #estimator = Flow_estimator(args, method=blend_method)\n",
    "        estimator = Flow_estimator(args, blend_method)\n",
    "        print('model: ', args.model)\n",
    "        print('warp method: ', warp)\n",
    "\n",
    "            \n",
    "    ID = []\n",
    "    #out_images = []\n",
    "    #results = []\n",
    "    p = []\n",
    "    s = []\n",
    "    fail = 0\n",
    "    for id in range(img_num):\n",
    "        scene = scene_images[id]\n",
    "        target = target_images[id]        \n",
    "        source = scene[source_id]  \n",
    "        if blend_method in ['life', 'raft', 'biraft', 'ms', 'twins', 'occ', 'twins-twostage', 'twins-onestage']:\n",
    "            out, result = eval(id, scene, target, blend_method=blend_method, save_root=save_root, source=source, blend_type=blend_type, estimator=estimator, with_mask=with_mask, use_colormap=use_colormap, heatmap=heatmap, draw=draw, save=save, warp=warp)\n",
    "        elif blend_method == 'pdc':\n",
    "            out, result = eval(id, scene, target, blend_method=blend_method, save_root=save_root, source=source, blend_type=blend_type, flow_estimator=flow_estimator, estimate_uncertainty=estimate_uncertainty, with_mask=with_mask, use_colormap=use_colormap, heatmap=heatmap, draw=draw, save=save)\n",
    "        elif blend_method == 'homography':\n",
    "            out, result = eval(id, scene, target, blend_method=blend_method, save_root=save_root, source=source, blend_type=blend_type, with_mask=with_mask, detector=detector, use_colormap=use_colormap, heatmap=heatmap, draw=draw, save=save)\n",
    "        elif blend_method == 'SPSG':\n",
    "            out, result = eval(id, scene, target, blend_method=blend_method, save_root=save_root, source=source, blend_type=blend_type, matching=matching, with_mask=with_mask, use_colormap=use_colormap, heatmap=heatmap, draw=draw, save=save)\n",
    "        else:\n",
    "            raise ValueError('blend method not inplemented')\n",
    "        #out_images.append(out)\n",
    "        #results.append(result)\n",
    "        #ID.append(str(id).zfill(4))\n",
    "        \n",
    "        # Include Failures\n",
    "        p.append(result['p'])\n",
    "        s.append(result['s'])\n",
    "\n",
    "        # Exclude Failures\n",
    "        # p.append([result['p'][i] for i in range(len(result['p'])) if result['p'][i]!=-1])\n",
    "        # s.append([result['s'][i] for i in range(len(result['s'])) if result['s'][i]!=-1])\n",
    "        fail = fail + result['fail']\n",
    "    \n",
    "    # p_array = np.asarray(p).flatten()\n",
    "    # s_array = np.asarray(s).flatten()\n",
    "    p_array = np.asarray([item for sub in p for item in sub])    \n",
    "    s_array = np.asarray([item for sub in s for item in sub])\n",
    "    # print(p_array)\n",
    "    # print(s_array)\n",
    "    # mask = ~np.isnan(p_array)\n",
    "    # p_array = p_array[mask]\n",
    "    # s_array = s_array[mask]\n",
    "    \n",
    "    print(blend_method+'\\t PSNR: {:.2f}/{:.2f}\\t SSIM: {:.2f}/{:.2f}\\t fail: {:.2f}%({}/{})'\n",
    "        .format(np.mean(p_array), \n",
    "                np.median(p_array),\n",
    "                np.mean(s_array), \n",
    "                np.median(s_array),\n",
    "                fail*1.0/total*100,\n",
    "                fail, total))\n",
    "    \n",
    "    #draw_result(ID, out_images, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blend type: viewpoint\n",
      "input 10x10 scene images\n",
      "input 10 target images\n",
      "blend method:  SPSG\n",
      "Running inference on device \"cuda\"\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "SPSG\t PSNR: 11.77/13.89\t SSIM: 0.34/0.63\t fail: 19.00%(19/100)\n",
      "blend type: light\n",
      "input 10x10 scene images\n",
      "input 10 target images\n",
      "blend method:  SPSG\n",
      "Running inference on device \"cuda\"\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "SPSG\t PSNR: 11.30/13.52\t SSIM: 0.34/0.67\t fail: 21.00%(21/100)\n",
      "blend type: deformation\n",
      "input 10x10 scene images\n",
      "input 10 target images\n",
      "blend method:  SPSG\n",
      "Running inference on device \"cuda\"\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "SPSG\t PSNR: 10.00/10.93\t SSIM: 0.17/0.29\t fail: 12.00%(12/100)\n",
      "blend type: scale\n",
      "input 10x10 scene images\n",
      "input 10 target images\n",
      "blend method:  SPSG\n",
      "Running inference on device \"cuda\"\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "SPSG\t PSNR: 2.46/0.00\t SSIM: -0.70/-1.00\t fail: 78.00%(78/100)\n",
      "blend type: occlusion\n",
      "input 10x10 scene images\n",
      "input 10 target images\n",
      "blend method:  SPSG\n",
      "Running inference on device \"cuda\"\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "SPSG\t PSNR: 10.76/10.46\t SSIM: 0.36/0.39\t fail: 3.00%(3/100)\n"
     ]
    }
   ],
   "source": [
    "''' 数据集格式\n",
    "|-deformation (scene images)\n",
    "    |-0000_deformation_0.jpg\n",
    "    |-0000_deformation_1.jpg\n",
    "    |-...\n",
    "    |-0001_deformation_0.jpg\n",
    "    |-...\n",
    "|-light\n",
    "|-occlusion\n",
    "|-scale\n",
    "|-viewpoint\n",
    "|-0000.jpg (target image)\n",
    "|-0001.jpg\n",
    "|-...\n",
    "'''\n",
    "# life / multiscale / twins 记得改模型路径！！！\n",
    "# !!! pip install kornia == 0.6.3\n",
    "types = ['viewpoint', 'light', 'deformation', 'scale', 'occlusion']\n",
    "blend_type = 'viewpoint'\n",
    "blend_method = 'SPSG'\n",
    "warp = 'grid_sample'\n",
    "with_mask = True\n",
    "draw = False \n",
    "save = False\n",
    "use_colormap = False # mask output with colormap\n",
    "heatmap = False # output metrics heatmap\n",
    "img_num = 10\n",
    "scn_num = 10\n",
    "start_img_id = 0\n",
    "start_scene_id = 0\n",
    "source_id = 1\n",
    "\n",
    " \n",
    "time = datetime.datetime.now()\n",
    "suffix = datetime.datetime.strftime(time, '%m%d%H%M')        \n",
    "save_root = os.path.join('./assets/output', blend_method+'_output_'+suffix+'_'+str(start_img_id))\n",
    "\n",
    "for blend_type in types:\n",
    "    print('blend type: '+blend_type)\n",
    "    save_dir = os.path.join(save_root, blend_type)\n",
    "    if save:\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "    run(blend_type=blend_type, \n",
    "        blend_method=blend_method, \n",
    "        warp=warp, \n",
    "        img_num=img_num, \n",
    "        scn_num=scn_num, \n",
    "        source_id=source_id, \n",
    "        with_mask=with_mask, \n",
    "        use_colormap=use_colormap,\n",
    "        multisample=True, \n",
    "        folder=\"minions\", \n",
    "        start_img_id=start_img_id, \n",
    "        start_scene_id = start_scene_id, \n",
    "        draw=draw, \n",
    "        save=save, \n",
    "        save_root=save_dir,\n",
    "        detector=\"SIFT\",\n",
    "        heatmap=heatmap)\n",
    "\n",
    "# sift / pdc\n",
    "# run(blend_type='occlusion', blend_method='homography', warp='grid_sample', img_num=1, scn_num=10, source_id=1, with_mask=True, multisample=True, folder=\"minions\", start_img_id=0, start_scene_id = 0, draw=False, save=False, detector=\"SIFT\")\n",
    "\n",
    "# SPSG\n",
    "# run(blend_type='deformation', blend_method='SPSG', warp='grid_sample', img_num=1, scn_num=10, source_id=1, with_mask=True, multisample=True, folder=\"minions\", start_img_id=0, start_scene_id = 0, draw=False, save=False, detector=\"SIFT\")\n",
    "\n",
    "# LIFE - life->pretrain.pth / raft->RAFT_latest.pth / biraft->biRAFT_latest.pth\n",
    "# sys.path.append('./LIFE')\n",
    "# sys.path.append('./LIFE/core')\n",
    "# run(blend_type='viewpoint', blend_method='biraft', warp='grid_sample', img_num=10, scn_num=10, source_id=1, with_mask=True, multisample=True, folder=\"minions\", start_img_id=0, start_scene_id = 0, draw=False, save=False, detector=\"SIFT\")\n",
    "\n",
    "\n",
    "# MultiScale - MultiScale_latest.pth\n",
    "# sys.path.append('./MultiScale')\n",
    "# sys.path.append('./MultiScale/core')\n",
    "# run(blend_type='viewpoint', blend_method='ms', warp='grid_sample', img_num=10, scn_num=10, source_id=1, with_mask=True, multisample=True, folder=\"minions\", start_img_id=0, start_scene_id = 0, draw=False, save=False, detector=\"SIFT\")\n",
    "\n",
    "# Occ - RAFT_twins_bs12_ep20.pth\n",
    "# sys.path.append('./Occ')\n",
    "# sys.path.append('./Occ/core')\n",
    "# run(blend_type='viewpoint', blend_method='occ', warp='grid_sample', img_num=10, scn_num=10, source_id=1, with_mask=True, multisample=True, folder=\"minions\", start_img_id=0, start_scene_id = 0, draw=False, save=False, detector=\"SIFT\")\n",
    "\n",
    "# Twins - best_twins_ms.pth / twins-twostage.pth / twins-onestage.pth\n",
    "# sys.path.append('./Twins')\n",
    "# sys.path.append('./Twins/core')\n",
    "# run(blend_type='viewpoint', blend_method='twins', warp='grid_sample', img_num=10, scn_num=10, source_id=1, with_mask=True, multisample=True, folder=\"minions\", start_img_id=0, start_scene_id = 0, draw=False, save=False, detector=\"SIFT\")\n",
    "# run(blend_type='deformation', blend_method='twins-onestage', warp='grid_sample', img_num=10, scn_num=10, source_id=1, with_mask=True, multisample=True, folder=\"minions\", start_img_id=0, start_scene_id = 0, draw=False, save=False, detector=\"SIFT\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24d476ac703b729f04d8ac5d768e8057e3dd62c7be786439cca60b67954f1529"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
