{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"]=\"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"]=\"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import sys\n",
    "from skimage import io\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import warnings\n",
    "\n",
    "# RANSAC-Flow Path\n",
    "sys.path.append('./RANSAC-Flow')\n",
    "sys.path.append('./RANSAC-Flow/utils')\n",
    "sys.path.append('./RANSAC-Flow/model')\n",
    "sys.path.append('./RANSAC-Flow/quick_start')\n",
    "from coarseAlignFeatMatch import CoarseAlign\n",
    "import outil\n",
    "import model as model\n",
    "import PIL.Image as Image \n",
    "import kornia.geometry as tgm\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# metrics\n",
    "from skimage.metrics import mean_squared_error as mse \n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import datetime\n",
    "# psnr\n",
    "from skimage.util.dtype import dtype_range\n",
    "from skimage._shared.utils import warn, check_shape_equality\n",
    "# ssim\n",
    "from skimage.util.arraycrop import crop\n",
    "from scipy.ndimage import uniform_filter, gaussian_filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_input_images(scene_images, target_images):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    num = len(scene_images)\n",
    "    plt.subplot(221), plt.imshow(scene_images[0]), plt.axis('off')\n",
    "    plt.subplot(222), plt.imshow(target_images[0]), plt.axis('off')\n",
    "    plt.subplot(223), plt.imshow(scene_images[num-1]), plt.axis('off')\n",
    "    plt.subplot(224), plt.imshow(target_images[num-1]), plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend(out, source, scene, blend_type, mask=None):\n",
    "    out = np.array(out)\n",
    "    source = np.array(source)\n",
    "    scene = np.array(scene)\n",
    "    if mask is None:\n",
    "        intensity = np.linalg.norm(out, axis=2)\n",
    "        mask = (intensity == 0)[:,:,np.newaxis]   \n",
    "    else:\n",
    "        mask = mask    \n",
    "    if blend_type == 'light':\n",
    "        result = (out * (1 - mask) + source * mask).astype(np.uint8)\n",
    "    else:\n",
    "        result = (out * (1 - mask) + scene * mask).astype(np.uint8) \n",
    "    return result, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(image_true, image_test, mask=None):\n",
    "    check_shape_equality(image_true, image_test)    \n",
    "\n",
    "    if image_true.dtype != image_test.dtype:\n",
    "        warn(\"Inputs have mismatched dtype. Setting data_range based on \"\n",
    "                \"im_true.\", stacklevel=2)\n",
    "    dmin, dmax = dtype_range[image_true.dtype.type]\n",
    "    true_min, true_max = np.min(image_true), np.max(image_true)\n",
    "    if true_max > dmax or true_min < dmin:\n",
    "        raise ValueError(\n",
    "            \"im_true has intensity values outside the range expected for \"\n",
    "            \"its data type. Please manually specify the data_range\")\n",
    "    if true_min >= 0:\n",
    "        # most common case (255 for uint8, 1 for float)\n",
    "        data_range = dmax\n",
    "    else:\n",
    "        data_range = dmax - dmin\n",
    "    \n",
    "    image_true = image_true.astype(np.float64)\n",
    "    image_test = image_test.astype(np.float64)\n",
    "    if mask is None:                      \n",
    "        err = np.mean((image_true - image_test) ** 2, dtype=np.float64)\n",
    "    else:\n",
    "        mask = 1-mask\n",
    "        cnt = np.count_nonzero(mask) * image_true.shape[2]\n",
    "        sum = np.sum((image_true*mask - image_test*mask)**2)    \n",
    "        err = sum/cnt\n",
    "        '''\n",
    "        plt.figure(facecolor='white')\n",
    "        plt.subplot(121), plt.imshow(image_true.astype(np.uint8)*mask)\n",
    "        plt.subplot(122), plt.imshow(image_test.astype(np.uint8)*mask)\n",
    "        '''\n",
    "    return 10 * np.log10((data_range ** 2) / err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSIM(im1, im2, multichannel=True, mask=None):\n",
    "    check_shape_equality(im1, im2)\n",
    "\n",
    "    if multichannel:\n",
    "        # loop over channels\n",
    "        nch = im1.shape[-1]\n",
    "        mssim = np.empty(nch)\n",
    "        for ch in range(nch):\n",
    "            ch_result = SSIM(im1[..., ch], im2[..., ch], multichannel=False, mask=mask)\n",
    "            mssim[..., ch] = ch_result\n",
    "        mssim = mssim.mean()\n",
    "        return mssim\n",
    "\n",
    "    if im1.dtype != im2.dtype:\n",
    "        warn(\"Inputs have mismatched dtype.  Setting data_range based on im1.dtype.\", stacklevel=2)\n",
    "    dmin, dmax = dtype_range[im1.dtype.type]\n",
    "    data_range = dmax - dmin\n",
    "    \n",
    "    K1 = 0.01\n",
    "    K2 = 0.03\n",
    "    R = data_range\n",
    "    C1 = (K1 * R) ** 2\n",
    "    C2 = (K2 * R) ** 2\n",
    "\n",
    "    # ndimage filters need floating point data\n",
    "    im1 = im1.astype(np.float64)\n",
    "    im2 = im2.astype(np.float64)\n",
    "\n",
    "    if mask is None:\n",
    "        mask = np.zeros_like(im1)\n",
    "        x,y = np.nonzero(1-mask)\n",
    "    else:\n",
    "        x,y,_ = np.nonzero(1-mask)\n",
    "    im1_pixel = im1[x,y]\n",
    "    im2_pixel = im2[x,y]\n",
    "\n",
    "    ux = np.mean(im1_pixel)\n",
    "    uy = np.mean(im2_pixel)\n",
    "    uxy = np.mean(im1_pixel*im2_pixel)\n",
    "    vx = np.var(im1_pixel)\n",
    "    vy = np.var(im2_pixel)\n",
    "    vxy = uxy - ux*uy\n",
    "\n",
    "    ssim = (2*ux*uy+C1)*(2*vxy+C2)/((ux**2+uy**2+C1)*(vx+vy+C2))\n",
    "    return ssim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(id, output_images, masks, save_root, scene_images=None, source=None, blend_type='scale', with_mask=False, save=True):   \n",
    "    if blend_type != 'light' and len(output_images)!=len(scene_images):\n",
    "        raise ValueError('output images should have the same number as scene images')\n",
    "    if save:\n",
    "        save_file = os.path.join(save_root, 'output.txt')\n",
    "    result = {'p':[], 's':[], 'ce':[], 'fail':0}\n",
    "    print('id: {}'.format(str(id).zfill(4)))\n",
    "    if save:\n",
    "        with open(save_file, 'a') as f:\n",
    "            f.write('id: {}\\n'.format(str(id).zfill(4)))\n",
    "\n",
    "    for i, output in enumerate(output_images):\n",
    "        if output is None: \n",
    "            result['p'].append(-1)\n",
    "            result['s'].append(-1)\n",
    "            result['ce'].append(-1)\n",
    "            result['fail'] = result['fail']+1\n",
    "            print('no.{:2d}\\t Failed'.format(i))\n",
    "            if save:\n",
    "                with open(save_file, 'a') as f:\n",
    "                    f.write('no.{:2d}\\t Failed\\n'.format(i))\n",
    "            continue\n",
    "\n",
    "        if blend_type == 'light':\n",
    "            scene = source\n",
    "        else:\n",
    "            scene = scene_images[i]\n",
    "\n",
    "        # print(output.shape[:2], scene.shape[:2])\n",
    "        if not with_mask:\n",
    "            p = psnr(np.array(output), np.array(scene))\n",
    "            s = ssim(np.array(output), np.array(scene), multichannel=True)                \n",
    "        else:            \n",
    "            mask = masks[i]\n",
    "            p = PSNR(np.array(output), np.array(scene), mask=mask)\n",
    "            s = SSIM(np.array(output), np.array(scene), multichannel=True, mask=mask)                                \n",
    "            #plt.figure(facecolor='white')\n",
    "            #plt.subplot(121), plt.imshow(output*(1-mask)), plt.title('output'), plt.axis('off')\n",
    "            #plt.subplot(122), plt.imshow(scene*(1-mask)), plt.title('scene'), plt.axis('off')\n",
    "            \n",
    "        result['p'].append(round(p, 2))\n",
    "        result['s'].append(round(s, 2))            \n",
    "        #print('no.{:2d}\\t PSNR:{:.2f}\\t SSIM:{:.2f}\\t census error:{:.2f}'.format(i, p, s, ce))\n",
    "        print('no.{:2d}\\t PSNR:{:.2f}\\t SSIM:{:.2f}\\t'.format(i, p, s))\n",
    "        if save:\n",
    "            with open(save_file, 'a') as f:\n",
    "                f.write('no.{:2d}\\t PSNR:{:.2f}\\t SSIM:{:.2f}\\t\\n'.format(i, p, s))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_RANSAC(scene_images, target, coarseModel=None, network=None, source=None, blend_type='scale', save_root=None):\n",
    "    blends = []\n",
    "    masks = []    \n",
    "    for idx, scene in enumerate(scene_images):        \n",
    "        target = target.resize(scene.size)        \n",
    "        coarseModel.setSource(target)\n",
    "        coarseModel.setTarget(scene)\n",
    "\n",
    "        I2w, I2h = coarseModel.It.size\n",
    "        featt = F.normalize(network['netFeatCoarse'](coarseModel.ItTensor))\n",
    "                    \n",
    "        #### -- grid     \n",
    "        gridY = torch.linspace(-1, 1, steps = I2h).view(1, -1, 1, 1).expand(1, I2h,  I2w, 1)\n",
    "        gridX = torch.linspace(-1, 1, steps = I2w).view(1, 1, -1, 1).expand(1, I2h,  I2w, 1)\n",
    "        grid = torch.cat((gridX, gridY), dim=3).cuda() \n",
    "        warper = tgm.HomographyWarper(I2h,  I2w)\n",
    "\n",
    "        bestPara, InlierMask = coarseModel.getCoarse(np.zeros((I2h, I2w)))\n",
    "        bestPara = torch.from_numpy(bestPara).unsqueeze(0).cuda()\n",
    "\n",
    "        flowCoarse = warper.warp_grid(bestPara)        \n",
    "        I1_coarse = F.grid_sample(coarseModel.IsTensor, flowCoarse)\n",
    "        # I1_coarse_pil = transforms.ToPILImage()(I1_coarse.cpu().squeeze())\n",
    "\n",
    "        featsSample = F.normalize(network['netFeatCoarse'](I1_coarse.cuda()))\n",
    "\n",
    "        corr12 = network['netCorr'](featt, featsSample)\n",
    "        flowDown8 = network['netFlowCoarse'](corr12, False) ## output is with dimension B, 2, W, H\n",
    "\n",
    "        flowUp = F.interpolate(flowDown8, size=(grid.size()[1], grid.size()[2]), mode='bilinear')\n",
    "        flowUp = flowUp.permute(0, 2, 3, 1)\n",
    "\n",
    "        flowUp = flowUp + grid\n",
    "\n",
    "        flow12 = F.grid_sample(flowCoarse.permute(0, 3, 1, 2), flowUp).permute(0, 2, 3, 1).contiguous()\n",
    "\n",
    "        I1_fine = F.grid_sample(coarseModel.IsTensor, flow12)\n",
    "        I1_fine_pil = transforms.ToPILImage()(I1_fine.cpu().squeeze())\n",
    "        if blend_type == 'light':\n",
    "            I1_fine_pil = I1_fine_pil.resize(source.size)    \n",
    "        else:    \n",
    "            I1_fine_pil = I1_fine_pil.resize(scene.size)\n",
    "\n",
    "        blend_i, mask_i = blend(I1_fine_pil, source, scene, blend_type)\n",
    "        #blend_i = cv2.resize(blend_i, (ori_W, ori_H))\n",
    "        blends.append(blend_i)\n",
    "        masks.append(mask_i)\n",
    "        \n",
    "        \n",
    "    return blends, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(id, \n",
    "         scene_images, \n",
    "         target,           \n",
    "         save_root,          \n",
    "         blend_type='scale', \n",
    "         coarseModel=None,\n",
    "         network=None,\n",
    "         source=None,         \n",
    "         with_mask = False,\n",
    "         draw = True,\n",
    "         save = True,\n",
    "         ):   \n",
    "    '''\n",
    "    Args:\n",
    "        @id: (int) target image id, for logging\n",
    "        @scene_images: (list) test scene images\n",
    "        @target: (array) target image\n",
    "        @save_root: (string)         \n",
    "        @blend_type: (string, 'scale') ['scale', 'light', 'viewpoint']\n",
    "        @estimator: model to estimate when blend_method=='life'\n",
    "        @flow_estimator: model to estimate when blend_method=='pdc'\n",
    "        @estimate_uncertainty: check result uncertainty when blend_method=='pdc'\n",
    "        @matching: SPSG\n",
    "        @coarseModel & network: RANSAC-Flow\n",
    "        @source: source image to calculate metrics when blend_type=='lighting'\n",
    "        @detector: (string, 'SIFT) ['SIFT', 'ORB'] detector used in homography\n",
    "        @with_mask: (bool) calculate metrics with or without mask\n",
    "        @draw: (bool) show results or not\n",
    "        @save: (bool) save results or not\n",
    "        @warp: (string,'grid_sample') ['grid_sample', 'homography'] warp method for LIFE model\n",
    "    '''\n",
    "    out, mask = blend_RANSAC(scene_images, target, coarseModel=coarseModel, network=network, source=source, blend_type=blend_type, save_root=save_root)\n",
    "\n",
    "        \n",
    "    if blend_type == 'light':\n",
    "        result = metrics(id, out, mask, save_root=save_root, source=source, blend_type=blend_type, with_mask=with_mask, save=save)\n",
    "    else:\n",
    "        result = metrics(id, out, mask, save_root=save_root, scene_images =scene_images, blend_type=blend_type, with_mask=with_mask, save=save)\n",
    "    \n",
    "    #if not with_mask and draw:\n",
    "    if draw: \n",
    "        save_root = os.path.join(save_root, str(id).zfill(4))\n",
    "        if save and not os.path.exists(save_root):\n",
    "            os.makedirs(save_root)\n",
    "        for i in range(len(scene_images)): \n",
    "            if out[i] is None:\n",
    "                continue\n",
    "            title = 'PSNR: '+str(result['p'][i])+' SSIM: '+str(result['s'][i])\n",
    "            # plt.figure(figsize=(10,15), facecolor='white')      \n",
    "                        \n",
    "            # scene_images[i] = rescale(scene_images[i])\n",
    "            # out[i] = rescale(out[i])\n",
    "            plt.figure(facecolor='white')\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(target), plt.axis('off')# , plt.title('target '+str(id).zfill(4))        \n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(scene_images[i]), plt.axis('off')# , plt.title('scene '+str(i).zfill(4))        \n",
    "            plt.subplot(1, 3, 3)\n",
    "            if not with_mask:\n",
    "                plt.imshow(out[i]), plt.axis('off') #, plt.title(title)\n",
    "            else:\n",
    "                plt.imshow(out[i]*(1-mask[i])), plt.axis('off') #, plt.title(title)\n",
    "            if save: \n",
    "                #plt.figure(facecolor='white')\n",
    "                #plt.imshow(out[i]*(1-mask[i])), plt.title(title), plt.axis('off')\n",
    "                plt.savefig(os.path.join(save_root,str(i)+'_'+title+'.png'), dpi=200, bbox_inches='tight')\n",
    "                #io.imsave(os.path.join(save_root, str(i)+'_'+title+'.png'), out[i]) # cv2.resize(out[i],None,fx=0.25,fy=0.25)\n",
    "                # io.imsave(os.path.join(save_root, str(i)+'_out.png'), np.array(out[i]))\n",
    "                # io.imsave(os.path.join(save_root, str(i)+'_scene.png'), np.array(scene_images[i]))\n",
    "            plt.close()\n",
    "            \n",
    "    return (out, result)\n",
    "\n",
    "def rescale(img):\n",
    "    if img.shape[0] > img.shape[1]:\n",
    "        resize = cv2.flip(cv2.transpose(img), 0)\n",
    "        # region = img[140:500, 0:480]\n",
    "        # resize = cv2.resize(region, (640, 480))\n",
    "    return resize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(root = './assets/',\n",
    "        blend_type = 'scale',        \n",
    "        img_num = 5, \n",
    "        start_img_id = 0,\n",
    "        start_scene_id = 0,\n",
    "        scn_num = 10,\n",
    "        source_id = -1,\n",
    "        H = 480,\n",
    "        W = 640,\n",
    "        with_mask = False,\n",
    "        draw = True,\n",
    "        save = True,        \n",
    "        multisample=True,\n",
    "        folder=\"\",\n",
    "        ):\n",
    "    '''\n",
    "    Args:\n",
    "        @root: (string, './assets/') image data root\n",
    "        @blend_type: (string, 'scale) ['scale', 'light', 'viewpoint', 'deformation', 'occlusion']\n",
    "        @blend_method: (string, 'life') ['homography', 'pdc', 'life', 'raft', 'biraft', 'ms', 'occ', 'twins', 'twins-twostage', 'twins-onestage']\n",
    "        @img_num: (int, 5) number of test images\n",
    "        @start_img_id: (int, 0) test from image with id=start_img_id\n",
    "        @start_scene_id: (int, 0) test from scene image with id=start_scene_id\n",
    "        @scn_num: (int, 10) number of scene images per test image\n",
    "        @source_id: if blend_type=='light', source id should be specified for metrics calculation\n",
    "        @(W, H): resize images\n",
    "        @with_mask: caculate PSNR/SSIM with or without mask\n",
    "        @draw: (bool)\n",
    "        @save: (bool)\n",
    "        @detector: (string, 'SIFT') ['SIFT', 'ORB']\n",
    "        @multisample: (bool, True) if False(not one of blend_type), specify scene images folder\n",
    "        @warp: (string, 'grid_sample') ['grid_sample', 'homography'] warp method for LIFE model\n",
    "    Ouput:\n",
    "        folder '{blend_method}_output_{time}' with output images and output.txt(metrics) will be created under folder {blend_type}\n",
    "    '''\n",
    "    # path setting\n",
    "    if blend_type == 'light':\n",
    "        if source_id == -1:\n",
    "            raise FileExistsError('no source image id specified.')    \n",
    "    if multisample:\n",
    "        scene_root = os.path.join(root, blend_type)\n",
    "    else:\n",
    "        if folder==\"\":\n",
    "            raise FileNotFoundError(\"input folder name\")\n",
    "        scene_root = os.path.join(root, folder) \n",
    "    time = datetime.datetime.now()\n",
    "    suffix = datetime.datetime.strftime(time, '%m%d%H%M')\n",
    "    if not with_mask:\n",
    "        save_root = os.path.join(scene_root, 'ransac_output_'+suffix)\n",
    "    else:\n",
    "        save_root = os.path.join(scene_root, 'ransac_output_mask_'+suffix)\n",
    "    if save and not os.path.exists(save_root):\n",
    "        os.makedirs(save_root)\n",
    "\n",
    "    # data loading\n",
    "    if H > W:\n",
    "        H, W = W, H\n",
    "    scene_images = []\n",
    "    target_images = []    \n",
    "    for id in range(img_num):\n",
    "        id = id + start_img_id\n",
    "        scene_image = []\n",
    "        for i in range(start_scene_id, scn_num):\n",
    "            scene_path = os.path.join(scene_root, str(id).zfill(4) + \"_\" + blend_type + \"_\"+str(i)+\".jpg\")\n",
    "            scene = Image.open(scene_path).convert('RGB')\n",
    "            if scene.size[1] > scene.size[0]: # H > W\n",
    "                scene = scene.resize((H, W))\n",
    "            else:\n",
    "                scene = scene.resize((W, H))\n",
    "            scene_image.append(scene)\n",
    "        scene_images.append(scene_image)\n",
    "\n",
    "        target_path = os.path.join(root, str(id).zfill(4) + \".jpg\")\n",
    "        target_image = Image.open(target_path).convert('RGB')\n",
    "        if target_image.size[1] > target_image.size[0]: # H > W\n",
    "            target_image = target_image.resize((H, W))\n",
    "        else:\n",
    "            target_image = target_image.resize((W, H))     \n",
    "        target_images.append(target_image)\n",
    "    total = len(scene_images)*len(scene_images[0])\n",
    "    print('input {}x{} scene images'.format(len(scene_images), len(scene_images[0])))\n",
    "    print('input {} target images'.format(len(target_images)))\n",
    "    # show_input_images(scene_images, target_images)\n",
    "\n",
    "    # model loading\n",
    "    resumePth = './RANSAC-Flow/model/pretrained/MegaDepth_Theta1_Eta001_Grad1_0.774.pth' ## model for visualization\n",
    "    kernelSize = 7\n",
    "    ## Loading model\n",
    "    # Define Networks\n",
    "    network = {'netFeatCoarse' : model.FeatureExtractor(), \n",
    "            'netCorr'       : model.CorrNeigh(kernelSize),\n",
    "            'netFlowCoarse' : model.NetFlowCoarse(kernelSize), \n",
    "            'netMatch'      : model.NetMatchability(kernelSize),\n",
    "            }\n",
    "        \n",
    "\n",
    "    for key in list(network.keys()) : \n",
    "        network[key].cuda()        \n",
    "\n",
    "    # loading Network \n",
    "    param = torch.load(resumePth)\n",
    "    msg = 'Loading pretrained model from {}'.format(resumePth)\n",
    "    print (msg)\n",
    "\n",
    "    for key in list(param.keys()) : \n",
    "        network[key].load_state_dict( param[key] ) \n",
    "        network[key].eval()\n",
    "\n",
    "    nbScale = 7\n",
    "    coarseIter = 10000\n",
    "    coarsetolerance = 0.05\n",
    "    minSize = 400\n",
    "    imageNet = True # we can also use MOCO feature here\n",
    "    scaleR = 1.2 \n",
    "\n",
    "    coarseModel = CoarseAlign(nbScale, coarseIter, coarsetolerance, 'Homography', minSize, 1, True, imageNet, scaleR)\n",
    "            \n",
    "    ID = []\n",
    "    #out_images = []\n",
    "    #results = []\n",
    "    p = []\n",
    "    s = []\n",
    "    fail = 0\n",
    "    for id in range(img_num):\n",
    "        scene = scene_images[id]\n",
    "        target = target_images[id]\n",
    "        source = scene[source_id]  \n",
    "        out, result = eval(id, scene, target, save_root=save_root, source=source, blend_type=blend_type, coarseModel=coarseModel, network=network, with_mask=with_mask, draw=draw, save=save)\n",
    "        #out_images.append(out)\n",
    "        #results.append(result)\n",
    "        #ID.append(str(id).zfill(4))\n",
    "        \n",
    "        # p.append(result['p'])\n",
    "        # s.append(result['s'])\n",
    "        p.append([result['p'][i] for i in range(len(result['p'])) if result['p'][i]!=-1])\n",
    "        s.append([result['s'][i] for i in range(len(result['s'])) if result['s'][i]!=-1])\n",
    "        fail = fail + result['fail']\n",
    "    \n",
    "    # p_array = np.asarray(p).flatten()\n",
    "    # s_array = np.asarray(s).flatten()\n",
    "    p_array = np.asarray([item for sub in p for item in sub])\n",
    "    s_array = np.asarray([item for sub in s for item in sub])\n",
    "    #print(p_array)\n",
    "    print('RANSAC\\t PSNR: {:.2f}/{:.2f}\\t SSIM: {:.2f}/{:.2f}\\t fail: {:.2f}%({}/{})'\n",
    "        .format(np.mean(p_array), \n",
    "                np.median(p_array),\n",
    "                np.mean(s_array), \n",
    "                np.median(s_array),\n",
    "                fail*1.0/total*100,\n",
    "                fail, total))\n",
    "    \n",
    "    #draw_result(ID, out_images, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 数据集格式\n",
    "|-deformation (scene images)\n",
    "    |-0000_deformation_0.jpg\n",
    "    |-0000_deformation_1.jpg\n",
    "    |-...\n",
    "    |-0001_deformation_0.jpg\n",
    "    |-...\n",
    "|-light\n",
    "|-occlusion\n",
    "|-scale\n",
    "|-viewpoint\n",
    "|-0000.jpg (target image)\n",
    "\n",
    "|-0001.jpg\n",
    "|-...\n",
    "'''\n",
    "# RANSAC\n",
    "# pip install kornia==0.1.4.post2\n",
    "# kornia 版本太高会找不到warp_grid函数\n",
    "run(blend_type='occlusion', img_num=10, scn_num=10, source_id=1, with_mask=True, multisample=True, folder=\"minions\", start_img_id=0, start_scene_id = 0, draw=False, save=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "24d476ac703b729f04d8ac5d768e8057e3dd62c7be786439cca60b67954f1529"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
